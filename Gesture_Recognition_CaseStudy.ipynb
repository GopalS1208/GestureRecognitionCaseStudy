{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Recognition\n",
    "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started. Once you have completed the code you can download the notebook for making a submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from imageio import imread\n",
    "from skimage.transform import resize\n",
    "import datetime\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**data path: /home/datasets/Project_data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_path = '/home/datasets/Project_data/'\n",
    "train_doc = np.random.permutation(open(home_path + 'train.csv').readlines())\n",
    "val_doc = np.random.permutation(open(home_path + 'val.csv').readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(source_path, folder_list, batch_size):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    #create a list of image numbers you want to use for a particular video\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        y = shape_h\n",
    "        z = shape_w\n",
    "        num_batches = int(len(t)/batch_size) # calculate the number of batches\n",
    "        #remaining batches should be handled in a separate batch\n",
    "        remaining_batches = len(t) - num_batches * batch_size\n",
    "        x = len(img_idx)\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            batch_data = np.zeros((batch_size,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    image_resized = resize(image,(y, z))\n",
    "                    \n",
    "                    batch_data[folder,idx,:,:,0] = (image_resized[:,:,0])/255 #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,1] = (image_resized[:,:,1])/255 #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,2] = (image_resized[:,:,2])/255 #normalise and feed in the image\n",
    "                    \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "\n",
    "    # write the code for the remaining data points which are left after full batches\n",
    "        if remaining_batches !=0:\n",
    "            for batch in range(num_batches): # we iterate over the number of batches\n",
    "                batch_data = np.zeros((batch_size,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "                batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "                for folder in range(batch_size): # iterate over the batch_size\n",
    "                    imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                    for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                        image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "\n",
    "                        #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                        #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                        image_resized = resize(image,(y, z))\n",
    "\n",
    "                        batch_data[folder,idx,:,:,0] = (image_resized[:,:,0])/255 #normalise and feed in the image\n",
    "                        batch_data[folder,idx,:,:,1] = (image_resized[:,:,1])/255 #normalise and feed in the image\n",
    "                        batch_data[folder,idx,:,:,2] = (image_resized[:,:,2])/255 #normalise and feed in the image\n",
    "\n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting of Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot the training/validation accuracies/losses.\n",
    "\n",
    "def plot(history):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n",
    "    axes[0].plot(history.history['loss'])   \n",
    "    axes[0].plot(history.history['val_loss'])\n",
    "    axes[0].legend(['loss','val_loss'])\n",
    "\n",
    "    axes[1].plot(history.history['categorical_accuracy'])   \n",
    "    axes[1].plot(history.history['val_categorical_accuracy'])\n",
    "    axes[1].legend(['categorical_accuracy','val_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n"
     ]
    }
   ],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "train_path = home_path+'train'\n",
    "val_path = home_path+'val'\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Variables to be passed to each model\n",
    "def model_vars(img_idx,shape_h,shape_w,batch_size,num_epochs):\n",
    "    print(\"No of frames passed in each video :{}\".format(len(img_idx)))\n",
    "    return img_idx,shape_h,shape_w,batch_size,num_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Dropout, Flatten, BatchNormalization, Activation, Conv3D, MaxPooling3D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.1, patience = 10, verbose = 0, mode = \"auto\", epsilon = 1e-04, \n",
    "                       cooldown = 0, min_lr = 0)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1\n",
    "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv3DModel1(frames_to_sample,image_height,image_width):\n",
    "    \n",
    "    Input_shape=(frames_to_sample,image_height,image_width,3)\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(64, (3,3,3), padding='same', input_shape=Input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv3D(128, (3, 3,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv3D(256, (3, 3,3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv3D(256, (3, 3,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    optimiser = 'adam'\n",
    "    model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of frames passed in each video :10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 08:15:02.414364: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2024-07-04 08:15:02.414441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14800 MB memory:  -> device: 0, name: Quadro RTX 5000, pci bus id: 0000:1b:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d (Conv3D)             (None, 10, 120, 120, 64)  5248      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 10, 120, 120, 64)  0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 10, 120, 120, 64)  256      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 8, 118, 118, 128)  221312    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 8, 118, 118, 128)  0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 8, 118, 118, 128)  512      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3D  (None, 4, 59, 59, 128)   0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4, 59, 59, 128)    0         \n",
      "                                                                 \n",
      " conv3d_2 (Conv3D)           (None, 4, 59, 59, 256)    884992    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 4, 59, 59, 256)    0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 4, 59, 59, 256)   1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv3d_3 (Conv3D)           (None, 2, 57, 57, 256)    1769728   \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 2, 57, 57, 256)    0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 2, 57, 57, 256)   1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPooling  (None, 1, 28, 28, 256)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1, 28, 28, 256)    0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 200704)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               102760960 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 2565      \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 105,647,621\n",
      "Trainable params: 105,646,213\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_idx,shape_h,shape_w,batch_size,num_epochs = model_vars([6,8,10,12,14,16,20,22,24,26],120,120,30,15)\n",
    "conv_model1=Conv3DModel1(frames_to_sample=len(img_idx),image_height=shape_h,image_width=shape_w)\n",
    "conv_model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit` method to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch: 23\n",
      "validation_steps: 4\n"
     ]
    }
   ],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print(\"steps_per_epoch:\", steps_per_epoch)\n",
    "print(\"validation_steps:\", validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 105647621\n",
      "Source path =  /home/datasets/Project_data/train ; batch size = 30\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 08:15:18.383971: I tensorflow/stream_executor/cuda/cuda_dnn.cc:377] Loaded cuDNN version 8302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - ETA: 0s - loss: 84.3566 - categorical_accuracy: 0.3333Source path =  /home/datasets/Project_data/val ; batch size = 30\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 281.50885, saving model to model_init_2024-07-0408_14_48.111338/model-00001-84.35658-0.33333-281.50885-0.31667.h5\n",
      "23/23 [==============================] - 163s 7s/step - loss: 84.3566 - categorical_accuracy: 0.3333 - val_loss: 281.5089 - val_categorical_accuracy: 0.3167 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 22.6943 - categorical_accuracy: 0.4826\n",
      "Epoch 00002: val_loss improved from 281.50885 to 176.00504, saving model to model_init_2024-07-0408_14_48.111338/model-00002-22.69431-0.48261-176.00504-0.40833.h5\n",
      "23/23 [==============================] - 106s 5s/step - loss: 22.6943 - categorical_accuracy: 0.4826 - val_loss: 176.0050 - val_categorical_accuracy: 0.4083 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 10.6956 - categorical_accuracy: 0.5710\n",
      "Epoch 00003: val_loss improved from 176.00504 to 129.97876, saving model to model_init_2024-07-0408_14_48.111338/model-00003-10.69558-0.57101-129.97876-0.20833.h5\n",
      "23/23 [==============================] - 103s 5s/step - loss: 10.6956 - categorical_accuracy: 0.5710 - val_loss: 129.9788 - val_categorical_accuracy: 0.2083 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 9.3916 - categorical_accuracy: 0.5507\n",
      "Epoch 00004: val_loss improved from 129.97876 to 61.08829, saving model to model_init_2024-07-0408_14_48.111338/model-00004-9.39160-0.55072-61.08829-0.27500.h5\n",
      "23/23 [==============================] - 107s 5s/step - loss: 9.3916 - categorical_accuracy: 0.5507 - val_loss: 61.0883 - val_categorical_accuracy: 0.2750 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 5.7038 - categorical_accuracy: 0.5580\n",
      "Epoch 00005: val_loss improved from 61.08829 to 37.24286, saving model to model_init_2024-07-0408_14_48.111338/model-00005-5.70384-0.55797-37.24286-0.25000.h5\n",
      "23/23 [==============================] - 101s 5s/step - loss: 5.7038 - categorical_accuracy: 0.5580 - val_loss: 37.2429 - val_categorical_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 3.9087 - categorical_accuracy: 0.6014\n",
      "Epoch 00006: val_loss improved from 37.24286 to 36.82179, saving model to model_init_2024-07-0408_14_48.111338/model-00006-3.90867-0.60145-36.82179-0.21667.h5\n",
      "23/23 [==============================] - 101s 5s/step - loss: 3.9087 - categorical_accuracy: 0.6014 - val_loss: 36.8218 - val_categorical_accuracy: 0.2167 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 3.2506 - categorical_accuracy: 0.5696\n",
      "Epoch 00007: val_loss improved from 36.82179 to 24.68345, saving model to model_init_2024-07-0408_14_48.111338/model-00007-3.25057-0.56957-24.68345-0.26667.h5\n",
      "23/23 [==============================] - 106s 5s/step - loss: 3.2506 - categorical_accuracy: 0.5696 - val_loss: 24.6835 - val_categorical_accuracy: 0.2667 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 3.2654 - categorical_accuracy: 0.5391\n",
      "Epoch 00008: val_loss improved from 24.68345 to 23.56205, saving model to model_init_2024-07-0408_14_48.111338/model-00008-3.26535-0.53913-23.56205-0.23333.h5\n",
      "23/23 [==============================] - 105s 5s/step - loss: 3.2654 - categorical_accuracy: 0.5391 - val_loss: 23.5621 - val_categorical_accuracy: 0.2333 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 5.0020 - categorical_accuracy: 0.5565\n",
      "Epoch 00009: val_loss improved from 23.56205 to 17.26877, saving model to model_init_2024-07-0408_14_48.111338/model-00009-5.00198-0.55652-17.26877-0.24167.h5\n",
      "23/23 [==============================] - 101s 5s/step - loss: 5.0020 - categorical_accuracy: 0.5565 - val_loss: 17.2688 - val_categorical_accuracy: 0.2417 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 4.3579 - categorical_accuracy: 0.5580\n",
      "Epoch 00010: val_loss improved from 17.26877 to 12.61761, saving model to model_init_2024-07-0408_14_48.111338/model-00010-4.35785-0.55797-12.61761-0.44167.h5\n",
      "23/23 [==============================] - 101s 5s/step - loss: 4.3579 - categorical_accuracy: 0.5580 - val_loss: 12.6176 - val_categorical_accuracy: 0.4417 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 4.9247 - categorical_accuracy: 0.5899\n",
      "Epoch 00011: val_loss did not improve from 12.61761\n",
      "23/23 [==============================] - 99s 4s/step - loss: 4.9247 - categorical_accuracy: 0.5899 - val_loss: 17.2931 - val_categorical_accuracy: 0.2833 - lr: 0.0010\n",
      "Epoch 12/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 4.0014 - categorical_accuracy: 0.5551\n",
      "Epoch 00012: val_loss did not improve from 12.61761\n",
      "23/23 [==============================] - 102s 5s/step - loss: 4.0014 - categorical_accuracy: 0.5551 - val_loss: 324.4578 - val_categorical_accuracy: 0.4000 - lr: 0.0010\n",
      "Epoch 13/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 4.7321 - categorical_accuracy: 0.5377\n",
      "Epoch 00013: val_loss did not improve from 12.61761\n",
      "23/23 [==============================] - 97s 4s/step - loss: 4.7321 - categorical_accuracy: 0.5377 - val_loss: 208.8998 - val_categorical_accuracy: 0.2833 - lr: 0.0010\n",
      "Epoch 14/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 6.5562 - categorical_accuracy: 0.5116\n",
      "Epoch 00014: val_loss did not improve from 12.61761\n",
      "23/23 [==============================] - 99s 4s/step - loss: 6.5562 - categorical_accuracy: 0.5116 - val_loss: 58.5875 - val_categorical_accuracy: 0.3167 - lr: 0.0010\n",
      "Epoch 15/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 9.0759 - categorical_accuracy: 0.4928\n",
      "Epoch 00015: val_loss did not improve from 12.61761\n",
      "23/23 [==============================] - 99s 4s/step - loss: 9.0759 - categorical_accuracy: 0.4928 - val_loss: 55.4823 - val_categorical_accuracy: 0.3333 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", conv_model1.count_params())\n",
    "model1=conv_model1.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv3DModel2(frames_to_sample,image_height,image_width):\n",
    "    \n",
    "    Input_shape=(frames_to_sample,image_height,image_width,3)\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(32, (3,3,3), padding='same', input_shape=Input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv3D(32, (3, 3,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv3D(64, (3, 3,3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv3D(64, (3, 3,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    optimiser = 'adam'\n",
    "    model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of frames passed in each video :14\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_40 (Conv3D)          (None, 14, 120, 120, 32)  2624      \n",
      "                                                                 \n",
      " activation_60 (Activation)  (None, 14, 120, 120, 32)  0         \n",
      "                                                                 \n",
      " batch_normalization_40 (Bat  (None, 14, 120, 120, 32)  128      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv3d_41 (Conv3D)          (None, 12, 118, 118, 32)  27680     \n",
      "                                                                 \n",
      " activation_61 (Activation)  (None, 12, 118, 118, 32)  0         \n",
      "                                                                 \n",
      " batch_normalization_41 (Bat  (None, 12, 118, 118, 32)  128      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_20 (MaxPoolin  (None, 6, 59, 59, 32)    0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 6, 59, 59, 32)     0         \n",
      "                                                                 \n",
      " conv3d_42 (Conv3D)          (None, 6, 59, 59, 64)     55360     \n",
      "                                                                 \n",
      " activation_62 (Activation)  (None, 6, 59, 59, 64)     0         \n",
      "                                                                 \n",
      " batch_normalization_42 (Bat  (None, 6, 59, 59, 64)    256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv3d_43 (Conv3D)          (None, 4, 57, 57, 64)     110656    \n",
      "                                                                 \n",
      " activation_63 (Activation)  (None, 4, 57, 57, 64)     0         \n",
      "                                                                 \n",
      " batch_normalization_43 (Bat  (None, 4, 57, 57, 64)    256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_21 (MaxPoolin  (None, 2, 28, 28, 64)    0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 2, 28, 28, 64)     0         \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 100352)            0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 64)                6422592   \n",
      "                                                                 \n",
      " activation_64 (Activation)  (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 5)                 325       \n",
      "                                                                 \n",
      " activation_65 (Activation)  (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,620,005\n",
      "Trainable params: 6,619,621\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_idx,shape_h,shape_w,batch_size,num_epochs = model_vars([2,4,6,8,10,12,14,16,18,20,22,24,26,28],120,120,30,15)\n",
    "conv_model2=Conv3DModel2(frames_to_sample=len(img_idx),image_height=shape_h,image_width=shape_w)\n",
    "conv_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch: 23\n",
      "validation_steps: 4\n"
     ]
    }
   ],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print(\"steps_per_epoch:\", steps_per_epoch)\n",
    "print(\"validation_steps:\", validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 6620005\n",
      "Source path =  /home/datasets/Project_data/train ; batch size = 30\n",
      "Epoch 1/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 9.5838 - categorical_accuracy: 0.2551 Source path =  /home/datasets/Project_data/val ; batch size = 30\n",
      "\n",
      "Epoch 00001: val_loss improved from 8.75529 to 3.68361, saving model to model_init_2024-07-0309_48_30.696990/model-00001-9.58384-0.25507-3.68361-0.15833.h5\n",
      "23/23 [==============================] - 147s 6s/step - loss: 9.5838 - categorical_accuracy: 0.2551 - val_loss: 3.6836 - val_categorical_accuracy: 0.1583 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.8211 - categorical_accuracy: 0.2145\n",
      "Epoch 00002: val_loss improved from 3.68361 to 1.85973, saving model to model_init_2024-07-0309_48_30.696990/model-00002-1.82109-0.21449-1.85973-0.07500.h5\n",
      "23/23 [==============================] - 142s 6s/step - loss: 1.8211 - categorical_accuracy: 0.2145 - val_loss: 1.8597 - val_categorical_accuracy: 0.0750 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.5206 - categorical_accuracy: 0.2087\n",
      "Epoch 00003: val_loss improved from 1.85973 to 1.82232, saving model to model_init_2024-07-0309_48_30.696990/model-00003-1.52056-0.20870-1.82232-0.14167.h5\n",
      "23/23 [==============================] - 139s 6s/step - loss: 1.5206 - categorical_accuracy: 0.2087 - val_loss: 1.8223 - val_categorical_accuracy: 0.1417 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.5439 - categorical_accuracy: 0.2058\n",
      "Epoch 00004: val_loss did not improve from 1.82232\n",
      "23/23 [==============================] - 148s 7s/step - loss: 1.5439 - categorical_accuracy: 0.2058 - val_loss: 12.1566 - val_categorical_accuracy: 0.1500 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.5524 - categorical_accuracy: 0.2145\n",
      "Epoch 00005: val_loss did not improve from 1.82232\n",
      "23/23 [==============================] - 140s 6s/step - loss: 1.5524 - categorical_accuracy: 0.2145 - val_loss: 12.9630 - val_categorical_accuracy: 0.1750 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.5092 - categorical_accuracy: 0.2188\n",
      "Epoch 00006: val_loss did not improve from 1.82232\n",
      "23/23 [==============================] - 143s 6s/step - loss: 1.5092 - categorical_accuracy: 0.2188 - val_loss: 15.2863 - val_categorical_accuracy: 0.1583 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.5740 - categorical_accuracy: 0.2130\n",
      "Epoch 00007: val_loss did not improve from 1.82232\n",
      "23/23 [==============================] - 140s 6s/step - loss: 1.5740 - categorical_accuracy: 0.2130 - val_loss: 16.0308 - val_categorical_accuracy: 0.1417 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.5416 - categorical_accuracy: 0.1971\n",
      "Epoch 00008: val_loss did not improve from 1.82232\n",
      "23/23 [==============================] - 147s 7s/step - loss: 1.5416 - categorical_accuracy: 0.1971 - val_loss: 12.2053 - val_categorical_accuracy: 0.1583 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.5415 - categorical_accuracy: 0.1986\n",
      "Epoch 00009: val_loss did not improve from 1.82232\n",
      "23/23 [==============================] - 141s 6s/step - loss: 1.5415 - categorical_accuracy: 0.1986 - val_loss: 10.5343 - val_categorical_accuracy: 0.1583 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.5416 - categorical_accuracy: 0.1971\n",
      "Epoch 00010: val_loss did not improve from 1.82232\n",
      "23/23 [==============================] - 141s 6s/step - loss: 1.5416 - categorical_accuracy: 0.1971 - val_loss: 8.7828 - val_categorical_accuracy: 0.1333 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.5415 - categorical_accuracy: 0.1986\n",
      "Epoch 00011: val_loss did not improve from 1.82232\n",
      "23/23 [==============================] - 141s 6s/step - loss: 1.5415 - categorical_accuracy: 0.1986 - val_loss: 6.9127 - val_categorical_accuracy: 0.1417 - lr: 0.0010\n",
      "Epoch 12/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.5413 - categorical_accuracy: 0.2000\n",
      "Epoch 00012: val_loss did not improve from 1.82232\n",
      "23/23 [==============================] - 151s 7s/step - loss: 1.5413 - categorical_accuracy: 0.2000 - val_loss: 5.2450 - val_categorical_accuracy: 0.1667 - lr: 0.0010\n",
      "Epoch 13/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.5413 - categorical_accuracy: 0.1986\n",
      "Epoch 00013: val_loss did not improve from 1.82232\n",
      "23/23 [==============================] - 144s 7s/step - loss: 1.5413 - categorical_accuracy: 0.1986 - val_loss: 3.9274 - val_categorical_accuracy: 0.1583 - lr: 0.0010\n",
      "Epoch 14/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.5414 - categorical_accuracy: 0.1957\n",
      "Epoch 00014: val_loss did not improve from 1.82232\n",
      "23/23 [==============================] - 140s 6s/step - loss: 1.5414 - categorical_accuracy: 0.1957 - val_loss: 3.0150 - val_categorical_accuracy: 0.1250 - lr: 1.0000e-04\n",
      "Epoch 15/15\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.5412 - categorical_accuracy: 0.1986\n",
      "Epoch 00015: val_loss did not improve from 1.82232\n",
      "23/23 [==============================] - 143s 6s/step - loss: 1.5412 - categorical_accuracy: 0.1986 - val_loss: 2.1087 - val_categorical_accuracy: 0.1833 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", conv_model2.count_params())\n",
    "model2=conv_model2.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv3DModel3(frames_to_sample,image_height,image_width):\n",
    "    \n",
    "    Input_shape=(frames_to_sample,image_height,image_width,3)\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(64, (3,3,3), padding='same', input_shape=Input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "\n",
    "    model.add(Conv3D(128, (3, 3,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv3D(128, (3, 3,3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    \n",
    "    optimiser = 'adam'\n",
    "    model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of frames passed in each video :14\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_58 (Conv3D)          (None, 14, 120, 120, 64)  5248      \n",
      "                                                                 \n",
      " activation_78 (Activation)  (None, 14, 120, 120, 64)  0         \n",
      "                                                                 \n",
      " batch_normalization_56 (Bat  (None, 14, 120, 120, 64)  256      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_34 (MaxPoolin  (None, 7, 60, 60, 64)    0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_59 (Conv3D)          (None, 5, 58, 58, 128)    221312    \n",
      "                                                                 \n",
      " activation_79 (Activation)  (None, 5, 58, 58, 128)    0         \n",
      "                                                                 \n",
      " batch_normalization_57 (Bat  (None, 5, 58, 58, 128)   512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_35 (MaxPoolin  (None, 2, 29, 29, 128)   0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 2, 29, 29, 128)    0         \n",
      "                                                                 \n",
      " conv3d_60 (Conv3D)          (None, 2, 29, 29, 128)    442496    \n",
      "                                                                 \n",
      " activation_80 (Activation)  (None, 2, 29, 29, 128)    0         \n",
      "                                                                 \n",
      " batch_normalization_58 (Bat  (None, 2, 29, 29, 128)   512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_36 (MaxPoolin  (None, 1, 14, 14, 128)   0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 1, 14, 14, 128)    0         \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 25088)             0         \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 512)               12845568  \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,518,469\n",
      "Trainable params: 13,517,829\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_idx,shape_h,shape_w,batch_size,num_epochs = model_vars([2,4,6,8,10,12,14,16,18,20,22,24,26,28],120,120,50,15)\n",
    "conv_model3=Conv3DModel3(frames_to_sample=len(img_idx),image_height=shape_h,image_width=shape_w)\n",
    "conv_model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch: 14\n",
      "validation_steps: 2\n"
     ]
    }
   ],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print(\"steps_per_epoch:\", steps_per_epoch)\n",
    "print(\"validation_steps:\", validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 13518469\n",
      "Source path =  /home/datasets/Project_data/train ; batch size = 50\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-03 11:55:57.137030: W tensorflow/core/common_runtime/bfc_allocator.cc:463] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.40GiB (rounded to 2580480000)requested by op gradient_tape/sequential_15/max_pooling3d_34/MaxPool3D/MaxPool3DGrad\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2024-07-03 11:55:57.137134: I tensorflow/core/common_runtime/bfc_allocator.cc:1010] BFCAllocator dump for GPU_0_bfc\n",
      "2024-07-03 11:55:57.137153: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (256): \tTotal Chunks: 337, Chunks in use: 336. 84.2KiB allocated for chunks. 84.0KiB in use in bin. 44.0KiB client-requested in use in bin.\n",
      "2024-07-03 11:55:57.137165: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (512): \tTotal Chunks: 59, Chunks in use: 58. 29.8KiB allocated for chunks. 29.0KiB in use in bin. 29.0KiB client-requested in use in bin.\n",
      "2024-07-03 11:55:57.137175: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1024): \tTotal Chunks: 36, Chunks in use: 35. 39.2KiB allocated for chunks. 38.2KiB in use in bin. 36.5KiB client-requested in use in bin.\n",
      "2024-07-03 11:55:57.137201: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2048): \tTotal Chunks: 9, Chunks in use: 9. 20.0KiB allocated for chunks. 20.0KiB in use in bin. 18.0KiB client-requested in use in bin.\n",
      "2024-07-03 11:55:57.137211: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4096): \tTotal Chunks: 1, Chunks in use: 1. 5.0KiB allocated for chunks. 5.0KiB in use in bin. 5.0KiB client-requested in use in bin.\n",
      "2024-07-03 11:55:57.137222: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8192): \tTotal Chunks: 18, Chunks in use: 18. 187.2KiB allocated for chunks. 187.2KiB in use in bin. 181.2KiB client-requested in use in bin.\n",
      "2024-07-03 11:55:57.137233: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16384): \tTotal Chunks: 8, Chunks in use: 8. 172.8KiB allocated for chunks. 172.8KiB in use in bin. 162.0KiB client-requested in use in bin.\n",
      "2024-07-03 11:55:57.137244: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (32768): \tTotal Chunks: 1, Chunks in use: 0. 37.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-07-03 11:55:57.137254: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (65536): \tTotal Chunks: 6, Chunks in use: 6. 648.0KiB allocated for chunks. 648.0KiB in use in bin. 648.0KiB client-requested in use in bin.\n",
      "2024-07-03 11:55:57.137263: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (131072): \tTotal Chunks: 12, Chunks in use: 12. 2.50MiB allocated for chunks. 2.50MiB in use in bin. 2.32MiB client-requested in use in bin.\n",
      "2024-07-03 11:55:57.137273: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (262144): \tTotal Chunks: 9, Chunks in use: 9. 3.80MiB allocated for chunks. 3.80MiB in use in bin. 3.80MiB client-requested in use in bin.\n",
      "2024-07-03 11:55:57.137283: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (524288): \tTotal Chunks: 11, Chunks in use: 10. 9.27MiB allocated for chunks. 8.42MiB in use in bin. 8.02MiB client-requested in use in bin.\n",
      "2024-07-03 11:55:57.137292: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1048576): \tTotal Chunks: 3, Chunks in use: 3. 4.83MiB allocated for chunks. 4.83MiB in use in bin. 4.22MiB client-requested in use in bin.\n",
      "2024-07-03 11:55:57.137303: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2097152): \tTotal Chunks: 6, Chunks in use: 5. 18.16MiB allocated for chunks. 14.78MiB in use in bin. 13.50MiB client-requested in use in bin.\n",
      "2024-07-03 11:55:57.137314: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4194304): \tTotal Chunks: 3, Chunks in use: 3. 19.38MiB allocated for chunks. 19.38MiB in use in bin. 16.88MiB client-requested in use in bin.\n",
      "2024-07-03 11:55:57.137324: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8388608): \tTotal Chunks: 4, Chunks in use: 3. 46.38MiB allocated for chunks. 36.25MiB in use in bin. 31.25MiB client-requested in use in bin.\n",
      "2024-07-03 11:55:57.137337: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16777216): \tTotal Chunks: 3, Chunks in use: 3. 73.50MiB allocated for chunks. 73.50MiB in use in bin. 73.50MiB client-requested in use in bin.\n",
      "2024-07-03 11:55:57.137348: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (33554432): \tTotal Chunks: 6, Chunks in use: 5. 281.75MiB allocated for chunks. 232.75MiB in use in bin. 220.50MiB client-requested in use in bin.\n",
      "2024-07-03 11:55:57.137359: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (67108864): \tTotal Chunks: 2, Chunks in use: 2. 213.36MiB allocated for chunks. 213.36MiB in use in bin. 213.36MiB client-requested in use in bin.\n",
      "2024-07-03 11:55:57.137370: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (134217728): \tTotal Chunks: 3, Chunks in use: 2. 527.25MiB allocated for chunks. 392.00MiB in use in bin. 392.00MiB client-requested in use in bin.\n",
      "2024-07-03 11:55:57.137380: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (268435456): \tTotal Chunks: 11, Chunks in use: 8. 13.28GiB allocated for chunks. 9.19GiB in use in bin. 8.96GiB client-requested in use in bin.\n",
      "2024-07-03 11:55:57.137390: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] Bin for 2.40GiB was 256.00MiB, Chunk State: \n",
      "2024-07-03 11:55:57.137406: I tensorflow/core/common_runtime/bfc_allocator.cc:1039]   Size: 925.41MiB | Requested Size: 410.64MiB | in_use: 0 | bin_num: 20, prev:   Size: 307.62MiB | Requested Size: 307.62MiB | in_use: 1 | bin_num: -1\n",
      "2024-07-03 11:55:57.137417: I tensorflow/core/common_runtime/bfc_allocator.cc:1039]   Size: 1.59GiB | Requested Size: 307.62MiB | in_use: 0 | bin_num: 20, prev:   Size: 2.40GiB | Requested Size: 2.40GiB | in_use: 1 | bin_num: -1\n",
      "2024-07-03 11:55:57.137427: I tensorflow/core/common_runtime/bfc_allocator.cc:1039]   Size: 1.60GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 2.40GiB | Requested Size: 2.40GiB | in_use: 1 | bin_num: -1\n",
      "2024-07-03 11:55:57.137435: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 6864633856\n",
      "2024-07-03 11:55:57.137446: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1a4a000000 of size 2580480000 next 540\n",
      "2024-07-03 11:55:57.137454: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1ae3cf0000 of size 2580480000 next 544\n",
      "2024-07-03 11:55:57.137461: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f1b7d9e0000 of size 1703673856 next 18446744073709551615\n",
      "2024-07-03 11:55:57.137469: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 4294967296\n",
      "2024-07-03 11:55:57.137476: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1c46000000 of size 2580480000 next 539\n",
      "2024-07-03 11:55:57.137484: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f1cdfcf0000 of size 1714487296 next 18446744073709551615\n",
      "2024-07-03 11:55:57.137491: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 2147483648\n",
      "2024-07-03 11:55:57.137499: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1e50000000 of size 411041792 next 112\n",
      "2024-07-03 11:55:57.137508: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1e68800000 of size 120960000 next 538\n",
      "2024-07-03 11:55:57.137515: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1e6fb5b400 of size 322560000 next 500\n",
      "2024-07-03 11:55:57.137523: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1e82ef9400 of size 322560000 next 546\n",
      "2024-07-03 11:55:57.137530: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f1e96297400 of size 970361856 next 18446744073709551615\n",
      "2024-07-03 11:55:57.137538: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 1073741824\n",
      "2024-07-03 11:55:57.137546: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1ed0000000 of size 51380224 next 249\n",
      "2024-07-03 11:55:57.137585: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1ed3100000 of size 25690112 next 346\n",
      "2024-07-03 11:55:57.137593: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1ed4980000 of size 25690112 next 377\n",
      "2024-07-03 11:55:57.137601: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1ed6200000 of size 51380224 next 459\n",
      "2024-07-03 11:55:57.137608: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f1ed9300000 of size 51380224 next 63\n",
      "2024-07-03 11:55:57.137616: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1edc400000 of size 205520896 next 18\n",
      "2024-07-03 11:55:57.137623: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1ee8800000 of size 205520896 next 176\n",
      "2024-07-03 11:55:57.137632: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1ef4c00000 of size 102760448 next 222\n",
      "2024-07-03 11:55:57.137640: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1efae00000 of size 884736 next 502\n",
      "2024-07-03 11:55:57.137647: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1efaed8000 of size 2654208 next 482\n",
      "2024-07-03 11:55:57.137655: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1efb160000 of size 1769472 next 481\n",
      "2024-07-03 11:55:57.137663: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f1efb310000 of size 3538944 next 508\n",
      "2024-07-03 11:55:57.137670: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1efb670000 of size 1769472 next 507\n",
      "2024-07-03 11:55:57.137678: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1efb820000 of size 2228224 next 284\n",
      "2024-07-03 11:55:57.137685: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1efba40000 of size 12845056 next 283\n",
      "2024-07-03 11:55:57.137693: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1efc680000 of size 12845056 next 313\n",
      "2024-07-03 11:55:57.137701: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1efd2c0000 of size 25690112 next 395\n",
      "2024-07-03 11:55:57.137708: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1efeb40000 of size 38535168 next 81\n",
      "2024-07-03 11:55:57.137717: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1f01000000 of size 7077888 next 150\n",
      "2024-07-03 11:55:57.137724: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1f016c0000 of size 51380224 next 492\n",
      "2024-07-03 11:55:57.137732: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1f047c0000 of size 51380224 next 515\n",
      "2024-07-03 11:55:57.137739: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f1f078c0000 of size 141819904 next 18446744073709551615\n",
      "2024-07-03 11:55:57.137747: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 536870912\n",
      "2024-07-03 11:55:57.137755: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1f10000000 of size 536870912 next 18446744073709551615\n",
      "2024-07-03 11:55:57.137763: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 536870912\n",
      "2024-07-03 11:55:57.137770: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1f30000000 of size 536870912 next 18446744073709551615\n",
      "2024-07-03 11:55:57.137778: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 33554432\n",
      "2024-07-03 11:55:57.137786: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1f56000000 of size 3538944 next 423\n",
      "2024-07-03 11:55:57.137793: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f1f56360000 of size 10616832 next 75\n",
      "2024-07-03 11:55:57.137800: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1f56d80000 of size 7077888 next 106\n",
      "2024-07-03 11:55:57.137808: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1f57440000 of size 12320768 next 18446744073709551615\n",
      "2024-07-03 11:55:57.139202: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 8388608\n",
      "2024-07-03 11:55:57.139212: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb0000000 of size 3538944 next 146\n",
      "2024-07-03 11:55:57.139220: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb0360000 of size 110592 next 325\n",
      "2024-07-03 11:55:57.139228: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb037b000 of size 110592 next 301\n",
      "2024-07-03 11:55:57.139236: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb0396000 of size 221184 next 31\n",
      "2024-07-03 11:55:57.139244: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb03cc000 of size 442368 next 53\n",
      "2024-07-03 11:55:57.139251: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb0438000 of size 884736 next 56\n",
      "2024-07-03 11:55:57.139259: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb0510000 of size 221184 next 238\n",
      "2024-07-03 11:55:57.139266: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb0546000 of size 110592 next 264\n",
      "2024-07-03 11:55:57.139274: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb0561000 of size 110592 next 203\n",
      "2024-07-03 11:55:57.139281: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb057c000 of size 442368 next 38\n",
      "2024-07-03 11:55:57.139288: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb05e8000 of size 884736 next 39\n",
      "2024-07-03 11:55:57.139296: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb06c0000 of size 221184 next 332\n",
      "2024-07-03 11:55:57.139303: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb06f6000 of size 221184 next 277\n",
      "2024-07-03 11:55:57.139311: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb072c000 of size 868352 next 18446744073709551615\n",
      "2024-07-03 11:55:57.139319: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 16777216\n",
      "2024-07-03 11:55:57.139326: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb0800000 of size 221184 next 363\n",
      "2024-07-03 11:55:57.139334: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb0836000 of size 221184 next 307\n",
      "2024-07-03 11:55:57.139341: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb086c000 of size 442368 next 306\n",
      "2024-07-03 11:55:57.139348: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb08d8000 of size 442368 next 337\n",
      "2024-07-03 11:55:57.139356: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb0944000 of size 442368 next 336\n",
      "2024-07-03 11:55:57.139363: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb09b0000 of size 442368 next 370\n",
      "2024-07-03 11:55:57.139371: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb0a1c000 of size 442368 next 369\n",
      "2024-07-03 11:55:57.139378: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb0a88000 of size 884736 next 473\n",
      "2024-07-03 11:55:57.139386: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb0b60000 of size 884736 next 446\n",
      "2024-07-03 11:55:57.139393: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb0c38000 of size 884736 next 435\n",
      "2024-07-03 11:55:57.139401: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb0d10000 of size 884736 next 428\n",
      "2024-07-03 11:55:57.139408: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f1fb0de8000 of size 884736 next 70\n",
      "2024-07-03 11:55:57.139416: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb0ec0000 of size 3538944 next 100\n",
      "2024-07-03 11:55:57.139423: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb1220000 of size 6160384 next 18446744073709551615\n",
      "2024-07-03 11:55:57.139432: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 2097152\n",
      "2024-07-03 11:55:57.139731: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9800000 of size 256 next 1\n",
      "2024-07-03 11:55:57.139753: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9800100 of size 1280 next 2\n",
      "2024-07-03 11:55:57.139773: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9800600 of size 256 next 3\n",
      "2024-07-03 11:55:57.139792: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9800700 of size 256 next 4\n",
      "2024-07-03 11:55:57.139812: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9800800 of size 256 next 5\n",
      "2024-07-03 11:55:57.139831: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9800900 of size 256 next 6\n",
      "2024-07-03 11:55:57.139852: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9800a00 of size 256 next 9\n",
      "2024-07-03 11:55:57.139871: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9800b00 of size 256 next 80\n",
      "2024-07-03 11:55:57.139890: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9800c00 of size 256 next 78\n",
      "2024-07-03 11:55:57.139910: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9800d00 of size 256 next 47\n",
      "2024-07-03 11:55:57.139929: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9800e00 of size 256 next 13\n",
      "2024-07-03 11:55:57.139948: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9800f00 of size 256 next 14\n",
      "2024-07-03 11:55:57.139967: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9801000 of size 256 next 15\n",
      "2024-07-03 11:55:57.139988: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9801100 of size 2560 next 22\n",
      "2024-07-03 11:55:57.140007: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9801b00 of size 256 next 23\n",
      "2024-07-03 11:55:57.140027: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9801c00 of size 256 next 24\n",
      "2024-07-03 11:55:57.140046: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9801d00 of size 256 next 20\n",
      "2024-07-03 11:55:57.140065: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9801e00 of size 256 next 19\n",
      "2024-07-03 11:55:57.140084: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9801f00 of size 256 next 26\n",
      "2024-07-03 11:55:57.140103: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9802000 of size 256 next 30\n",
      "2024-07-03 11:55:57.140122: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9802100 of size 256 next 29\n",
      "2024-07-03 11:55:57.140142: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9802200 of size 256 next 37\n",
      "2024-07-03 11:55:57.140161: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9802300 of size 256 next 40\n",
      "2024-07-03 11:55:57.140181: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9802400 of size 512 next 193\n",
      "2024-07-03 11:55:57.140201: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9802600 of size 512 next 211\n",
      "2024-07-03 11:55:57.140221: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9802800 of size 512 next 168\n",
      "2024-07-03 11:55:57.140240: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9802a00 of size 512 next 157\n",
      "2024-07-03 11:55:57.140259: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9802c00 of size 512 next 215\n",
      "2024-07-03 11:55:57.140278: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9802e00 of size 256 next 208\n",
      "2024-07-03 11:55:57.140298: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9802f00 of size 256 next 213\n",
      "2024-07-03 11:55:57.140317: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9803000 of size 256 next 32\n",
      "2024-07-03 11:55:57.140337: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9803100 of size 256 next 33\n",
      "2024-07-03 11:55:57.140402: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9803200 of size 256 next 34\n",
      "2024-07-03 11:55:57.140426: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9803300 of size 2048 next 199\n",
      "2024-07-03 11:55:57.140446: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9803b00 of size 256 next 173\n",
      "2024-07-03 11:55:57.140465: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9803c00 of size 256 next 181\n",
      "2024-07-03 11:55:57.140484: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9803d00 of size 256 next 192\n",
      "2024-07-03 11:55:57.140503: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9803e00 of size 256 next 190\n",
      "2024-07-03 11:55:57.140523: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9803f00 of size 256 next 212\n",
      "2024-07-03 11:55:57.140542: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9804000 of size 256 next 216\n",
      "2024-07-03 11:55:57.140561: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9804100 of size 256 next 179\n",
      "2024-07-03 11:55:57.140581: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9804200 of size 256 next 170\n",
      "2024-07-03 11:55:57.140600: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9804300 of size 256 next 103\n",
      "2024-07-03 11:55:57.140619: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9804400 of size 256 next 186\n",
      "2024-07-03 11:55:57.140638: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9804500 of size 256 next 92\n",
      "2024-07-03 11:55:57.140657: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9804600 of size 256 next 41\n",
      "2024-07-03 11:55:57.140677: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9804700 of size 256 next 42\n",
      "2024-07-03 11:55:57.140696: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9804800 of size 256 next 43\n",
      "2024-07-03 11:55:57.140715: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9804900 of size 512 next 61\n",
      "2024-07-03 11:55:57.140734: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9804b00 of size 512 next 62\n",
      "2024-07-03 11:55:57.140754: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9804d00 of size 512 next 60\n",
      "2024-07-03 11:55:57.140773: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9804f00 of size 256 next 59\n",
      "2024-07-03 11:55:57.140792: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9805000 of size 256 next 48\n",
      "2024-07-03 11:55:57.140811: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9805100 of size 256 next 49\n",
      "2024-07-03 11:55:57.140831: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9805200 of size 256 next 50\n",
      "2024-07-03 11:55:57.140851: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9805300 of size 256 next 72\n",
      "2024-07-03 11:55:57.140870: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9805400 of size 256 next 71\n",
      "2024-07-03 11:55:57.140889: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9805500 of size 256 next 54\n",
      "2024-07-03 11:55:57.140909: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9805600 of size 256 next 55\n",
      "2024-07-03 11:55:57.140929: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9805700 of size 21504 next 7\n",
      "2024-07-03 11:55:57.140950: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980ab00 of size 10496 next 73\n",
      "2024-07-03 11:55:57.140970: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980d400 of size 256 next 246\n",
      "2024-07-03 11:55:57.140989: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980d500 of size 256 next 247\n",
      "2024-07-03 11:55:57.141010: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980d600 of size 1024 next 248\n",
      "2024-07-03 11:55:57.141029: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980da00 of size 256 next 250\n",
      "2024-07-03 11:55:57.141049: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980db00 of size 256 next 251\n",
      "2024-07-03 11:55:57.141068: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980dc00 of size 256 next 300\n",
      "2024-07-03 11:55:57.141087: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980dd00 of size 256 next 302\n",
      "2024-07-03 11:55:57.141106: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980de00 of size 256 next 303\n",
      "2024-07-03 11:55:57.141126: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980df00 of size 256 next 304\n",
      "2024-07-03 11:55:57.141145: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980e000 of size 256 next 305\n",
      "2024-07-03 11:55:57.141164: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980e100 of size 256 next 308\n",
      "2024-07-03 11:55:57.141183: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980e200 of size 256 next 309\n",
      "2024-07-03 11:55:57.141203: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980e300 of size 256 next 310\n",
      "2024-07-03 11:55:57.141222: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980e400 of size 256 next 311\n",
      "2024-07-03 11:55:57.141241: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980e500 of size 256 next 312\n",
      "2024-07-03 11:55:57.141260: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980e600 of size 256 next 314\n",
      "2024-07-03 11:55:57.141279: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980e700 of size 256 next 323\n",
      "2024-07-03 11:55:57.141299: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980e800 of size 256 next 324\n",
      "2024-07-03 11:55:57.141318: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980e900 of size 256 next 326\n",
      "2024-07-03 11:55:57.141337: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980ea00 of size 256 next 327\n",
      "2024-07-03 11:55:57.141357: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980eb00 of size 256 next 328\n",
      "2024-07-03 11:55:57.141376: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980ec00 of size 256 next 329\n",
      "2024-07-03 11:55:57.141394: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980ed00 of size 256 next 330\n",
      "2024-07-03 11:55:57.141414: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980ee00 of size 256 next 331\n",
      "2024-07-03 11:55:57.141433: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980ef00 of size 256 next 333\n",
      "2024-07-03 11:55:57.141453: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980f000 of size 256 next 334\n",
      "2024-07-03 11:55:57.141472: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980f100 of size 256 next 317\n",
      "2024-07-03 11:55:57.141492: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980f200 of size 1280 next 318\n",
      "2024-07-03 11:55:57.141512: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980f700 of size 256 next 315\n",
      "2024-07-03 11:55:57.141531: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980f800 of size 256 next 316\n",
      "2024-07-03 11:55:57.141550: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980f900 of size 256 next 319\n",
      "2024-07-03 11:55:57.141569: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980fa00 of size 256 next 320\n",
      "2024-07-03 11:55:57.141589: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980fb00 of size 256 next 322\n",
      "2024-07-03 11:55:57.141608: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980fc00 of size 256 next 28\n",
      "2024-07-03 11:55:57.141628: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb980fd00 of size 10496 next 65\n",
      "2024-07-03 11:55:57.141647: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9812600 of size 256 next 252\n",
      "2024-07-03 11:55:57.141667: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9812700 of size 256 next 255\n",
      "2024-07-03 11:55:57.141686: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9812800 of size 256 next 256\n",
      "2024-07-03 11:55:57.141704: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9812900 of size 256 next 257\n",
      "2024-07-03 11:55:57.141724: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9812a00 of size 256 next 260\n",
      "2024-07-03 11:55:57.141743: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9812b00 of size 256 next 261\n",
      "2024-07-03 11:55:57.141762: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9812c00 of size 256 next 262\n",
      "2024-07-03 11:55:57.141782: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9812d00 of size 256 next 263\n",
      "2024-07-03 11:55:57.141801: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9812e00 of size 256 next 265\n",
      "2024-07-03 11:55:57.141821: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9812f00 of size 256 next 266\n",
      "2024-07-03 11:55:57.141840: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9813000 of size 256 next 267\n",
      "2024-07-03 11:55:57.141859: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9813100 of size 256 next 268\n",
      "2024-07-03 11:55:57.141878: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9813200 of size 256 next 269\n",
      "2024-07-03 11:55:57.141897: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9813300 of size 256 next 270\n",
      "2024-07-03 11:55:57.141917: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9813400 of size 256 next 272\n",
      "2024-07-03 11:55:57.141936: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9813500 of size 256 next 273\n",
      "2024-07-03 11:55:57.141955: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9813600 of size 256 next 274\n",
      "2024-07-03 11:55:57.141974: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9813700 of size 256 next 275\n",
      "2024-07-03 11:55:57.141994: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9813800 of size 256 next 276\n",
      "2024-07-03 11:55:57.142013: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9813900 of size 256 next 278\n",
      "2024-07-03 11:55:57.142032: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9813a00 of size 256 next 253\n",
      "2024-07-03 11:55:57.142053: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9813b00 of size 5120 next 254\n",
      "2024-07-03 11:55:57.142073: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9814f00 of size 256 next 279\n",
      "2024-07-03 11:55:57.142092: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9815000 of size 256 next 280\n",
      "2024-07-03 11:55:57.142111: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9815100 of size 256 next 281\n",
      "2024-07-03 11:55:57.142130: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9815200 of size 256 next 282\n",
      "2024-07-03 11:55:57.142150: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9815300 of size 256 next 285\n",
      "2024-07-03 11:55:57.142169: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9815400 of size 256 next 286\n",
      "2024-07-03 11:55:57.142189: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9815500 of size 256 next 287\n",
      "2024-07-03 11:55:57.142208: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9815600 of size 256 next 288\n",
      "2024-07-03 11:55:57.142227: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9815700 of size 256 next 289\n",
      "2024-07-03 11:55:57.142246: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9815800 of size 256 next 291\n",
      "2024-07-03 11:55:57.142265: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9815900 of size 256 next 293\n",
      "2024-07-03 11:55:57.142285: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9815a00 of size 256 next 294\n",
      "2024-07-03 11:55:57.142304: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9815b00 of size 256 next 295\n",
      "2024-07-03 11:55:57.142323: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9815c00 of size 256 next 296\n",
      "2024-07-03 11:55:57.142342: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9815d00 of size 256 next 297\n",
      "2024-07-03 11:55:57.142362: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9815e00 of size 256 next 298\n",
      "2024-07-03 11:55:57.142381: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9815f00 of size 256 next 299\n",
      "2024-07-03 11:55:57.142400: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9816000 of size 256 next 290\n",
      "2024-07-03 11:55:57.142420: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9816100 of size 1280 next 86\n",
      "2024-07-03 11:55:57.142439: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9816600 of size 256 next 89\n",
      "2024-07-03 11:55:57.142459: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9816700 of size 256 next 90\n",
      "2024-07-03 11:55:57.142477: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9816800 of size 256 next 91\n",
      "2024-07-03 11:55:57.142497: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9816900 of size 256 next 182\n",
      "2024-07-03 11:55:57.142516: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9816a00 of size 256 next 93\n",
      "2024-07-03 11:55:57.142536: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9816b00 of size 512 next 94\n",
      "2024-07-03 11:55:57.142555: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9816d00 of size 512 next 96\n",
      "2024-07-03 11:55:57.142575: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9816f00 of size 512 next 97\n",
      "2024-07-03 11:55:57.142594: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9817100 of size 256 next 98\n",
      "2024-07-03 11:55:57.142614: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9817200 of size 256 next 210\n",
      "2024-07-03 11:55:57.142633: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9817300 of size 256 next 195\n",
      "2024-07-03 11:55:57.142652: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9817400 of size 256 next 209\n",
      "2024-07-03 11:55:57.142672: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9817500 of size 10240 next 197\n",
      "2024-07-03 11:55:57.142692: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9819d00 of size 256 next 202\n",
      "2024-07-03 11:55:57.142711: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9819e00 of size 256 next 174\n",
      "2024-07-03 11:55:57.142730: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9819f00 of size 256 next 201\n",
      "2024-07-03 11:55:57.142750: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981a000 of size 256 next 188\n",
      "2024-07-03 11:55:57.142769: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981a100 of size 256 next 185\n",
      "2024-07-03 11:55:57.142788: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981a200 of size 256 next 109\n",
      "2024-07-03 11:55:57.142807: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981a300 of size 256 next 191\n",
      "2024-07-03 11:55:57.142827: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981a400 of size 256 next 177\n",
      "2024-07-03 11:55:57.142846: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981a500 of size 256 next 217\n",
      "2024-07-03 11:55:57.142865: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981a600 of size 256 next 218\n",
      "2024-07-03 11:55:57.142884: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981a700 of size 256 next 219\n",
      "2024-07-03 11:55:57.142904: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981a800 of size 256 next 220\n",
      "2024-07-03 11:55:57.142924: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981a900 of size 2048 next 221\n",
      "2024-07-03 11:55:57.142943: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981b100 of size 256 next 223\n",
      "2024-07-03 11:55:57.142962: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981b200 of size 256 next 224\n",
      "2024-07-03 11:55:57.142982: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981b300 of size 256 next 226\n",
      "2024-07-03 11:55:57.143001: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981b400 of size 256 next 227\n",
      "2024-07-03 11:55:57.143020: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981b500 of size 256 next 228\n",
      "2024-07-03 11:55:57.143039: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981b600 of size 256 next 229\n",
      "2024-07-03 11:55:57.143058: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981b700 of size 256 next 230\n",
      "2024-07-03 11:55:57.143078: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981b800 of size 256 next 231\n",
      "2024-07-03 11:55:57.143097: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981b900 of size 256 next 233\n",
      "2024-07-03 11:55:57.143116: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981ba00 of size 256 next 234\n",
      "2024-07-03 11:55:57.143159: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981bb00 of size 256 next 235\n",
      "2024-07-03 11:55:57.143179: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981bc00 of size 256 next 236\n",
      "2024-07-03 11:55:57.143205: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981bd00 of size 256 next 237\n",
      "2024-07-03 11:55:57.143217: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981be00 of size 256 next 239\n",
      "2024-07-03 11:55:57.143229: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981bf00 of size 256 next 240\n",
      "2024-07-03 11:55:57.143240: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981c000 of size 256 next 241\n",
      "2024-07-03 11:55:57.143252: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981c100 of size 256 next 243\n",
      "2024-07-03 11:55:57.143263: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981c200 of size 256 next 244\n",
      "2024-07-03 11:55:57.143275: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981c300 of size 256 next 245\n",
      "2024-07-03 11:55:57.143287: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981c400 of size 256 next 68\n",
      "2024-07-03 11:55:57.143299: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981c500 of size 10752 next 84\n",
      "2024-07-03 11:55:57.143311: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981ef00 of size 1024 next 99\n",
      "2024-07-03 11:55:57.143323: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981f300 of size 1024 next 101\n",
      "2024-07-03 11:55:57.143334: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981f700 of size 1024 next 102\n",
      "2024-07-03 11:55:57.143346: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981fb00 of size 256 next 184\n",
      "2024-07-03 11:55:57.143358: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981fc00 of size 512 next 194\n",
      "2024-07-03 11:55:57.143369: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb981fe00 of size 512 next 206\n",
      "2024-07-03 11:55:57.143381: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9820000 of size 256 next 200\n",
      "2024-07-03 11:55:57.143393: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9820100 of size 256 next 196\n",
      "2024-07-03 11:55:57.143405: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9820200 of size 256 next 104\n",
      "2024-07-03 11:55:57.143416: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9820300 of size 1024 next 105\n",
      "2024-07-03 11:55:57.143428: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9820700 of size 1024 next 107\n",
      "2024-07-03 11:55:57.143439: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9820b00 of size 1024 next 108\n",
      "2024-07-03 11:55:57.143451: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9820f00 of size 256 next 36\n",
      "2024-07-03 11:55:57.143463: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9821000 of size 256 next 79\n",
      "2024-07-03 11:55:57.143475: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9821100 of size 256 next 207\n",
      "2024-07-03 11:55:57.143486: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9821200 of size 256 next 205\n",
      "2024-07-03 11:55:57.143498: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9821300 of size 1024 next 110\n",
      "2024-07-03 11:55:57.143510: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9821700 of size 2048 next 113\n",
      "2024-07-03 11:55:57.143521: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9821f00 of size 256 next 114\n",
      "2024-07-03 11:55:57.143533: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9822000 of size 256 next 74\n",
      "2024-07-03 11:55:57.143545: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9822100 of size 256 next 117\n",
      "2024-07-03 11:55:57.143559: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9822200 of size 256 next 118\n",
      "2024-07-03 11:55:57.143571: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9822300 of size 256 next 119\n",
      "2024-07-03 11:55:57.143583: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9822400 of size 256 next 120\n",
      "2024-07-03 11:55:57.143594: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9822500 of size 256 next 121\n",
      "2024-07-03 11:55:57.143606: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9822600 of size 256 next 122\n",
      "2024-07-03 11:55:57.143617: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9822700 of size 256 next 123\n",
      "2024-07-03 11:55:57.143629: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9822800 of size 256 next 124\n",
      "2024-07-03 11:55:57.143641: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9822900 of size 256 next 125\n",
      "2024-07-03 11:55:57.143652: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9822a00 of size 256 next 126\n",
      "2024-07-03 11:55:57.143664: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9822b00 of size 512 next 127\n",
      "2024-07-03 11:55:57.143676: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9822d00 of size 512 next 128\n",
      "2024-07-03 11:55:57.143688: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9822f00 of size 512 next 129\n",
      "2024-07-03 11:55:57.143699: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9823100 of size 1024 next 130\n",
      "2024-07-03 11:55:57.143711: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9823500 of size 1024 next 131\n",
      "2024-07-03 11:55:57.143723: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9823900 of size 1792 next 88\n",
      "2024-07-03 11:55:57.143735: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9824000 of size 20736 next 87\n",
      "2024-07-03 11:55:57.143747: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9829100 of size 1024 next 132\n",
      "2024-07-03 11:55:57.143759: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9829500 of size 1024 next 133\n",
      "2024-07-03 11:55:57.143771: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9829900 of size 1024 next 134\n",
      "2024-07-03 11:55:57.143783: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9829d00 of size 2048 next 135\n",
      "2024-07-03 11:55:57.143795: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb982a500 of size 10240 next 136\n",
      "2024-07-03 11:55:57.143806: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb982cd00 of size 256 next 137\n",
      "2024-07-03 11:55:57.143818: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb982ce00 of size 20736 next 138\n",
      "2024-07-03 11:55:57.143830: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9831f00 of size 256 next 139\n",
      "2024-07-03 11:55:57.143842: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9832000 of size 256 next 140\n",
      "2024-07-03 11:55:57.143853: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9832100 of size 256 next 141\n",
      "2024-07-03 11:55:57.143865: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9832200 of size 884736 next 142\n",
      "2024-07-03 11:55:57.143877: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb990a200 of size 512 next 143\n",
      "2024-07-03 11:55:57.143889: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb990a400 of size 512 next 144\n",
      "2024-07-03 11:55:57.143900: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb990a600 of size 512 next 145\n",
      "2024-07-03 11:55:57.143912: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb990a800 of size 1024 next 147\n",
      "2024-07-03 11:55:57.143924: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb990ac00 of size 1024 next 148\n",
      "2024-07-03 11:55:57.143972: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb990b000 of size 1024 next 149\n",
      "2024-07-03 11:55:57.143984: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb990b400 of size 1024 next 151\n",
      "2024-07-03 11:55:57.143996: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb990b800 of size 1024 next 152\n",
      "2024-07-03 11:55:57.144008: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb990bc00 of size 1024 next 153\n",
      "2024-07-03 11:55:57.144020: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb990c000 of size 2048 next 154\n",
      "2024-07-03 11:55:57.144032: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb990c800 of size 10240 next 155\n",
      "2024-07-03 11:55:57.144044: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb990f000 of size 256 next 156\n",
      "2024-07-03 11:55:57.144056: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb990f100 of size 256 next 180\n",
      "2024-07-03 11:55:57.144067: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb990f200 of size 256 next 158\n",
      "2024-07-03 11:55:57.144079: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb990f300 of size 256 next 159\n",
      "2024-07-03 11:55:57.144091: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb990f400 of size 256 next 160\n",
      "2024-07-03 11:55:57.144102: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb990f500 of size 256 next 161\n",
      "2024-07-03 11:55:57.144114: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb990f600 of size 256 next 162\n",
      "2024-07-03 11:55:57.144126: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb990f700 of size 256 next 163\n",
      "2024-07-03 11:55:57.144137: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb990f800 of size 256 next 164\n",
      "2024-07-03 11:55:57.144149: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb990f900 of size 256 next 165\n",
      "2024-07-03 11:55:57.144161: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb990fa00 of size 256 next 166\n",
      "2024-07-03 11:55:57.144173: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb990fb00 of size 256 next 167\n",
      "2024-07-03 11:55:57.144184: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb990fc00 of size 256 next 83\n",
      "2024-07-03 11:55:57.144196: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb990fd00 of size 256 next 58\n",
      "2024-07-03 11:55:57.144208: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb990fe00 of size 256 next 85\n",
      "2024-07-03 11:55:57.144219: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb990ff00 of size 256 next 169\n",
      "2024-07-03 11:55:57.144232: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9910000 of size 1536 next 172\n",
      "2024-07-03 11:55:57.144244: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9910600 of size 256 next 67\n",
      "2024-07-03 11:55:57.144256: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9910700 of size 256 next 66\n",
      "2024-07-03 11:55:57.144268: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9910800 of size 256 next 52\n",
      "2024-07-03 11:55:57.144279: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9910900 of size 256 next 51\n",
      "2024-07-03 11:55:57.144291: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9910a00 of size 256 next 8\n",
      "2024-07-03 11:55:57.144303: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9910b00 of size 256 next 12\n",
      "2024-07-03 11:55:57.144315: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9910c00 of size 256 next 11\n",
      "2024-07-03 11:55:57.144326: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9910d00 of size 256 next 10\n",
      "2024-07-03 11:55:57.144338: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9910e00 of size 256 next 21\n",
      "2024-07-03 11:55:57.144519: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9910f00 of size 256 next 175\n",
      "2024-07-03 11:55:57.144537: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9911000 of size 256 next 198\n",
      "2024-07-03 11:55:57.144552: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9911100 of size 1024 next 189\n",
      "2024-07-03 11:55:57.144567: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9911500 of size 512 next 57\n",
      "2024-07-03 11:55:57.144583: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9911700 of size 512 next 204\n",
      "2024-07-03 11:55:57.144598: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9911900 of size 1024 next 187\n",
      "2024-07-03 11:55:57.144613: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9911d00 of size 10496 next 116\n",
      "2024-07-03 11:55:57.144630: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9914600 of size 210688 next 16\n",
      "2024-07-03 11:55:57.144646: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9947d00 of size 221184 next 76\n",
      "2024-07-03 11:55:57.144662: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb997dd00 of size 221184 next 69\n",
      "2024-07-03 11:55:57.144677: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99b3d00 of size 10496 next 225\n",
      "2024-07-03 11:55:57.144693: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99b6600 of size 256 next 335\n",
      "2024-07-03 11:55:57.144709: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99b6700 of size 256 next 338\n",
      "2024-07-03 11:55:57.144724: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99b6800 of size 256 next 339\n",
      "2024-07-03 11:55:57.144739: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99b6900 of size 256 next 340\n",
      "2024-07-03 11:55:57.144754: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99b6a00 of size 256 next 341\n",
      "2024-07-03 11:55:57.144770: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99b6b00 of size 256 next 342\n",
      "2024-07-03 11:55:57.144784: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99b6c00 of size 256 next 343\n",
      "2024-07-03 11:55:57.144800: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99b6d00 of size 256 next 344\n",
      "2024-07-03 11:55:57.144815: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99b6e00 of size 256 next 345\n",
      "2024-07-03 11:55:57.144830: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99b6f00 of size 256 next 347\n",
      "2024-07-03 11:55:57.144846: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99b7000 of size 256 next 348\n",
      "2024-07-03 11:55:57.144861: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99b7100 of size 256 next 351\n",
      "2024-07-03 11:55:57.144876: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99b7200 of size 256 next 354\n",
      "2024-07-03 11:55:57.144891: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99b7300 of size 256 next 355\n",
      "2024-07-03 11:55:57.144906: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99b7400 of size 256 next 356\n",
      "2024-07-03 11:55:57.144921: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99b7500 of size 256 next 361\n",
      "2024-07-03 11:55:57.144937: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99b7600 of size 256 next 358\n",
      "2024-07-03 11:55:57.144952: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99b7700 of size 256 next 359\n",
      "2024-07-03 11:55:57.144967: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99b7800 of size 256 next 360\n",
      "2024-07-03 11:55:57.144982: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99b7900 of size 256 next 349\n",
      "2024-07-03 11:55:57.144998: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99b7a00 of size 1280 next 350\n",
      "2024-07-03 11:55:57.145073: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99b7f00 of size 14592 next 259\n",
      "2024-07-03 11:55:57.145091: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99bb800 of size 10496 next 258\n",
      "2024-07-03 11:55:57.145106: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99be100 of size 10496 next 292\n",
      "2024-07-03 11:55:57.145121: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c0a00 of size 10496 next 321\n",
      "2024-07-03 11:55:57.145137: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c3300 of size 256 next 432\n",
      "2024-07-03 11:55:57.145152: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c3400 of size 256 next 362\n",
      "2024-07-03 11:55:57.145167: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c3500 of size 256 next 364\n",
      "2024-07-03 11:55:57.145182: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c3600 of size 256 next 365\n",
      "2024-07-03 11:55:57.145198: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c3700 of size 256 next 366\n",
      "2024-07-03 11:55:57.145213: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c3800 of size 256 next 430\n",
      "2024-07-03 11:55:57.145228: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c3900 of size 256 next 368\n",
      "2024-07-03 11:55:57.145243: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c3a00 of size 256 next 371\n",
      "2024-07-03 11:55:57.145259: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c3b00 of size 256 next 372\n",
      "2024-07-03 11:55:57.145274: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c3c00 of size 256 next 373\n",
      "2024-07-03 11:55:57.145289: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c3d00 of size 256 next 452\n",
      "2024-07-03 11:55:57.145305: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c3e00 of size 256 next 375\n",
      "2024-07-03 11:55:57.145320: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c3f00 of size 256 next 376\n",
      "2024-07-03 11:55:57.145335: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c4000 of size 256 next 378\n",
      "2024-07-03 11:55:57.145350: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c4100 of size 256 next 424\n",
      "2024-07-03 11:55:57.145366: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c4200 of size 256 next 382\n",
      "2024-07-03 11:55:57.145381: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c4300 of size 256 next 383\n",
      "2024-07-03 11:55:57.145396: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c4400 of size 256 next 384\n",
      "2024-07-03 11:55:57.145411: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c4500 of size 256 next 385\n",
      "2024-07-03 11:55:57.145427: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c4600 of size 256 next 386\n",
      "2024-07-03 11:55:57.145442: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c4700 of size 256 next 387\n",
      "2024-07-03 11:55:57.145458: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c4800 of size 256 next 388\n",
      "2024-07-03 11:55:57.145473: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c4900 of size 256 next 389\n",
      "2024-07-03 11:55:57.145489: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c4a00 of size 256 next 380\n",
      "2024-07-03 11:55:57.145504: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c4b00 of size 1280 next 381\n",
      "2024-07-03 11:55:57.145537: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c5000 of size 256 next 390\n",
      "2024-07-03 11:55:57.145555: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c5100 of size 256 next 391\n",
      "2024-07-03 11:55:57.145575: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c5200 of size 256 next 392\n",
      "2024-07-03 11:55:57.145594: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c5300 of size 256 next 393\n",
      "2024-07-03 11:55:57.145613: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c5400 of size 256 next 394\n",
      "2024-07-03 11:55:57.145632: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c5500 of size 256 next 396\n",
      "2024-07-03 11:55:57.145651: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c5600 of size 1536 next 353\n",
      "2024-07-03 11:55:57.145671: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c5c00 of size 10496 next 352\n",
      "2024-07-03 11:55:57.145689: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c8500 of size 256 next 397\n",
      "2024-07-03 11:55:57.145709: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99c8600 of size 10496 next 398\n",
      "2024-07-03 11:55:57.145728: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99caf00 of size 256 next 399\n",
      "2024-07-03 11:55:57.145747: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cb000 of size 256 next 400\n",
      "2024-07-03 11:55:57.145765: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cb100 of size 256 next 401\n",
      "2024-07-03 11:55:57.145784: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cb200 of size 256 next 402\n",
      "2024-07-03 11:55:57.145803: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cb300 of size 256 next 403\n",
      "2024-07-03 11:55:57.145822: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cb400 of size 256 next 404\n",
      "2024-07-03 11:55:57.145841: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cb500 of size 256 next 405\n",
      "2024-07-03 11:55:57.145860: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cb600 of size 256 next 406\n",
      "2024-07-03 11:55:57.145879: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cb700 of size 256 next 407\n",
      "2024-07-03 11:55:57.145898: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cb800 of size 256 next 408\n",
      "2024-07-03 11:55:57.145917: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cb900 of size 256 next 409\n",
      "2024-07-03 11:55:57.145936: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cba00 of size 256 next 410\n",
      "2024-07-03 11:55:57.145955: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cbb00 of size 256 next 411\n",
      "2024-07-03 11:55:57.145974: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cbc00 of size 1280 next 412\n",
      "2024-07-03 11:55:57.145993: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cc100 of size 256 next 413\n",
      "2024-07-03 11:55:57.146012: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cc200 of size 256 next 414\n",
      "2024-07-03 11:55:57.146031: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cc300 of size 256 next 415\n",
      "2024-07-03 11:55:57.146050: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cc400 of size 256 next 416\n",
      "2024-07-03 11:55:57.146069: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cc500 of size 256 next 417\n",
      "2024-07-03 11:55:57.146087: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cc600 of size 256 next 418\n",
      "2024-07-03 11:55:57.146106: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cc700 of size 256 next 419\n",
      "2024-07-03 11:55:57.146125: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cc800 of size 256 next 420\n",
      "2024-07-03 11:55:57.146146: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cc900 of size 256 next 421\n",
      "2024-07-03 11:55:57.146165: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cca00 of size 256 next 422\n",
      "2024-07-03 11:55:57.146184: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99ccb00 of size 256 next 439\n",
      "2024-07-03 11:55:57.146203: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99ccc00 of size 256 next 447\n",
      "2024-07-03 11:55:57.146222: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99ccd00 of size 256 next 433\n",
      "2024-07-03 11:55:57.146241: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cce00 of size 512 next 493\n",
      "2024-07-03 11:55:57.146260: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cd000 of size 512 next 454\n",
      "2024-07-03 11:55:57.146279: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cd200 of size 512 next 429\n",
      "2024-07-03 11:55:57.146298: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cd400 of size 256 next 427\n",
      "2024-07-03 11:55:57.146317: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cd500 of size 256 next 425\n",
      "2024-07-03 11:55:57.146336: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cd600 of size 256 next 445\n",
      "2024-07-03 11:55:57.146355: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cd700 of size 256 next 436\n",
      "2024-07-03 11:55:57.146374: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cd800 of size 256 next 434\n",
      "2024-07-03 11:55:57.146393: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cd900 of size 256 next 441\n",
      "2024-07-03 11:55:57.146412: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cda00 of size 256 next 458\n",
      "2024-07-03 11:55:57.146432: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cdb00 of size 3584 next 488\n",
      "2024-07-03 11:55:57.146451: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99ce900 of size 256 next 489\n",
      "2024-07-03 11:55:57.146469: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99cea00 of size 256 next 490\n",
      "2024-07-03 11:55:57.146488: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99ceb00 of size 512 next 214\n",
      "2024-07-03 11:55:57.146509: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb99ced00 of size 201472 next 18446744073709551615\n",
      "2024-07-03 11:55:57.146529: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 4194304\n",
      "2024-07-03 11:55:57.146549: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9a00000 of size 221184 next 171\n",
      "2024-07-03 11:55:57.146568: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9a36000 of size 110592 next 232\n",
      "2024-07-03 11:55:57.146588: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9a51000 of size 110592 next 82\n",
      "2024-07-03 11:55:57.146606: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9a6c000 of size 442368 next 77\n",
      "2024-07-03 11:55:57.146625: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9ad8000 of size 221184 next 271\n",
      "2024-07-03 11:55:57.146645: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b0e000 of size 20736 next 520\n",
      "2024-07-03 11:55:57.146665: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b13100 of size 30976 next 494\n",
      "2024-07-03 11:55:57.146684: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1aa00 of size 512 next 553\n",
      "2024-07-03 11:55:57.146703: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1ac00 of size 512 next 506\n",
      "2024-07-03 11:55:57.146723: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1ae00 of size 512 next 509\n",
      "2024-07-03 11:55:57.146742: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1b000 of size 512 next 510\n",
      "2024-07-03 11:55:57.146760: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1b200 of size 512 next 511\n",
      "2024-07-03 11:55:57.146779: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f1fb9b1b400 of size 1024 next 513\n",
      "2024-07-03 11:55:57.146799: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1b800 of size 2048 next 514\n",
      "2024-07-03 11:55:57.146818: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1c000 of size 256 next 516\n",
      "2024-07-03 11:55:57.146837: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1c100 of size 256 next 518\n",
      "2024-07-03 11:55:57.146856: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1c200 of size 256 next 519\n",
      "2024-07-03 11:55:57.146875: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1c300 of size 512 next 443\n",
      "2024-07-03 11:55:57.146895: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1c500 of size 512 next 462\n",
      "2024-07-03 11:55:57.146915: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1c700 of size 512 next 460\n",
      "2024-07-03 11:55:57.146933: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1c900 of size 512 next 451\n",
      "2024-07-03 11:55:57.146953: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1cb00 of size 512 next 431\n",
      "2024-07-03 11:55:57.146973: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1cd00 of size 256 next 523\n",
      "2024-07-03 11:55:57.146991: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1ce00 of size 256 next 524\n",
      "2024-07-03 11:55:57.147010: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1cf00 of size 256 next 525\n",
      "2024-07-03 11:55:57.147030: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1d000 of size 256 next 526\n",
      "2024-07-03 11:55:57.147049: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1d100 of size 256 next 527\n",
      "2024-07-03 11:55:57.147068: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1d200 of size 256 next 456\n",
      "2024-07-03 11:55:57.147087: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1d300 of size 256 next 357\n",
      "2024-07-03 11:55:57.147106: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1d400 of size 256 next 438\n",
      "2024-07-03 11:55:57.147125: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1d500 of size 256 next 448\n",
      "2024-07-03 11:55:57.147160: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1d600 of size 256 next 444\n",
      "2024-07-03 11:55:57.147179: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1d700 of size 512 next 440\n",
      "2024-07-03 11:55:57.147199: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1d900 of size 512 next 437\n",
      "2024-07-03 11:55:57.147218: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1db00 of size 512 next 457\n",
      "2024-07-03 11:55:57.147237: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1dd00 of size 512 next 455\n",
      "2024-07-03 11:55:57.147257: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1df00 of size 512 next 450\n",
      "2024-07-03 11:55:57.147276: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1e100 of size 1024 next 449\n",
      "2024-07-03 11:55:57.147295: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1e500 of size 1024 next 453\n",
      "2024-07-03 11:55:57.147314: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1e900 of size 1024 next 463\n",
      "2024-07-03 11:55:57.147333: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1ed00 of size 1024 next 367\n",
      "2024-07-03 11:55:57.147352: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1f100 of size 1024 next 464\n",
      "2024-07-03 11:55:57.147371: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1f500 of size 256 next 467\n",
      "2024-07-03 11:55:57.147390: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1f600 of size 256 next 468\n",
      "2024-07-03 11:55:57.147409: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1f700 of size 256 next 469\n",
      "2024-07-03 11:55:57.147428: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1f800 of size 256 next 470\n",
      "2024-07-03 11:55:57.147447: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1f900 of size 256 next 471\n",
      "2024-07-03 11:55:57.147466: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1fa00 of size 512 next 472\n",
      "2024-07-03 11:55:57.147485: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1fc00 of size 512 next 474\n",
      "2024-07-03 11:55:57.147504: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b1fe00 of size 512 next 475\n",
      "2024-07-03 11:55:57.147524: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b20000 of size 512 next 476\n",
      "2024-07-03 11:55:57.147542: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b20200 of size 512 next 477\n",
      "2024-07-03 11:55:57.147561: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b20400 of size 256 next 478\n",
      "2024-07-03 11:55:57.147580: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b20500 of size 256 next 479\n",
      "2024-07-03 11:55:57.147599: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b20600 of size 512 next 480\n",
      "2024-07-03 11:55:57.147618: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b20800 of size 512 next 483\n",
      "2024-07-03 11:55:57.147637: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b20a00 of size 512 next 484\n",
      "2024-07-03 11:55:57.147657: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b20c00 of size 512 next 485\n",
      "2024-07-03 11:55:57.147675: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b20e00 of size 512 next 486\n",
      "2024-07-03 11:55:57.147694: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b21000 of size 512 next 491\n",
      "2024-07-03 11:55:57.147713: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b21200 of size 512 next 442\n",
      "2024-07-03 11:55:57.147732: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b21400 of size 256 next 426\n",
      "2024-07-03 11:55:57.147751: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b21500 of size 256 next 379\n",
      "2024-07-03 11:55:57.147771: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b21600 of size 256 next 487\n",
      "2024-07-03 11:55:57.147790: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b21700 of size 512 next 495\n",
      "2024-07-03 11:55:57.147809: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b21900 of size 256 next 497\n",
      "2024-07-03 11:55:57.147828: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b21a00 of size 256 next 498\n",
      "2024-07-03 11:55:57.147847: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b21b00 of size 256 next 499\n",
      "2024-07-03 11:55:57.147866: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b21c00 of size 512 next 501\n",
      "2024-07-03 11:55:57.147885: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b21e00 of size 512 next 503\n",
      "2024-07-03 11:55:57.147904: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b22000 of size 512 next 504\n",
      "2024-07-03 11:55:57.147923: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b22200 of size 512 next 461\n",
      "2024-07-03 11:55:57.147943: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b22400 of size 20736 next 374\n",
      "2024-07-03 11:55:57.147962: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b27500 of size 10240 next 517\n",
      "2024-07-03 11:55:57.147981: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b29d00 of size 10496 next 466\n",
      "2024-07-03 11:55:57.148000: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b2c600 of size 20736 next 465\n",
      "2024-07-03 11:55:57.148019: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b31700 of size 20736 next 496\n",
      "2024-07-03 11:55:57.148039: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b36800 of size 2048 next 521\n",
      "2024-07-03 11:55:57.148058: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b37000 of size 10240 next 522\n",
      "2024-07-03 11:55:57.148077: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b39800 of size 256 next 528\n",
      "2024-07-03 11:55:57.148096: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b39900 of size 256 next 529\n",
      "2024-07-03 11:55:57.148116: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b39a00 of size 256 next 530\n",
      "2024-07-03 11:55:57.148135: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b39b00 of size 256 next 531\n",
      "2024-07-03 11:55:57.148153: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b39c00 of size 256 next 532\n",
      "2024-07-03 11:55:57.148172: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b39d00 of size 256 next 533\n",
      "2024-07-03 11:55:57.148191: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f1fb9b39e00 of size 768 next 563\n",
      "2024-07-03 11:55:57.148210: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b3a100 of size 256 next 534\n",
      "2024-07-03 11:55:57.148229: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b3a200 of size 256 next 535\n",
      "2024-07-03 11:55:57.148248: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b3a300 of size 256 next 565\n",
      "2024-07-03 11:55:57.148268: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f1fb9b3a400 of size 256 next 562\n",
      "2024-07-03 11:55:57.148287: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b3a500 of size 256 next 537\n",
      "2024-07-03 11:55:57.148305: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b3a600 of size 256 next 541\n",
      "2024-07-03 11:55:57.148324: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b3a700 of size 256 next 542\n",
      "2024-07-03 11:55:57.148343: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b3a800 of size 256 next 543\n",
      "2024-07-03 11:55:57.148362: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b3a900 of size 512 next 547\n",
      "2024-07-03 11:55:57.148381: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f1fb9b3ab00 of size 38144 next 242\n",
      "2024-07-03 11:55:57.148400: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9b44000 of size 442368 next 64\n",
      "2024-07-03 11:55:57.148420: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9bb0000 of size 884736 next 95\n",
      "2024-07-03 11:55:57.148439: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9c88000 of size 10240 next 115\n",
      "2024-07-03 11:55:57.148459: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f1fb9c8a800 of size 1529856 next 18446744073709551615\n",
      "2024-07-03 11:55:57.148478: I tensorflow/core/common_runtime/bfc_allocator.cc:1071]      Summary of in-use Chunks by size: \n",
      "2024-07-03 11:55:57.148504: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 336 Chunks of size 256 totalling 84.0KiB\n",
      "2024-07-03 11:55:57.148528: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 58 Chunks of size 512 totalling 29.0KiB\n",
      "2024-07-03 11:55:57.148551: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 26 Chunks of size 1024 totalling 26.0KiB\n",
      "2024-07-03 11:55:57.148574: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 6 Chunks of size 1280 totalling 7.5KiB\n",
      "2024-07-03 11:55:57.148596: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 1536 totalling 3.0KiB\n",
      "2024-07-03 11:55:57.148618: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1792 totalling 1.8KiB\n",
      "2024-07-03 11:55:57.148640: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 7 Chunks of size 2048 totalling 14.0KiB\n",
      "2024-07-03 11:55:57.148662: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 2560 totalling 2.5KiB\n",
      "2024-07-03 11:55:57.148684: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 3584 totalling 3.5KiB\n",
      "2024-07-03 11:55:57.148706: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 5120 totalling 5.0KiB\n",
      "2024-07-03 11:55:57.148729: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 6 Chunks of size 10240 totalling 60.0KiB\n",
      "2024-07-03 11:55:57.148753: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 10 Chunks of size 10496 totalling 102.5KiB\n",
      "2024-07-03 11:55:57.148775: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 10752 totalling 10.5KiB\n",
      "2024-07-03 11:55:57.148799: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 14592 totalling 14.2KiB\n",
      "2024-07-03 11:55:57.148821: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 6 Chunks of size 20736 totalling 121.5KiB\n",
      "2024-07-03 11:55:57.148844: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 21504 totalling 21.0KiB\n",
      "2024-07-03 11:55:57.148867: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 30976 totalling 30.2KiB\n",
      "2024-07-03 11:55:57.148890: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 6 Chunks of size 110592 totalling 648.0KiB\n",
      "2024-07-03 11:55:57.148913: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 201472 totalling 196.8KiB\n",
      "2024-07-03 11:55:57.148936: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 210688 totalling 205.8KiB\n",
      "2024-07-03 11:55:57.148959: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 10 Chunks of size 221184 totalling 2.11MiB\n",
      "2024-07-03 11:55:57.148981: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 9 Chunks of size 442368 totalling 3.80MiB\n",
      "2024-07-03 11:55:57.149003: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 868352 totalling 848.0KiB\n",
      "2024-07-03 11:55:57.149026: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 9 Chunks of size 884736 totalling 7.59MiB\n",
      "2024-07-03 11:55:57.149048: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1529856 totalling 1.46MiB\n",
      "2024-07-03 11:55:57.149071: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 1769472 totalling 3.38MiB\n",
      "2024-07-03 11:55:57.149093: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 2228224 totalling 2.12MiB\n",
      "2024-07-03 11:55:57.149115: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 2654208 totalling 2.53MiB\n",
      "2024-07-03 11:55:57.149138: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 3 Chunks of size 3538944 totalling 10.12MiB\n",
      "2024-07-03 11:55:57.149160: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 6160384 totalling 5.88MiB\n",
      "2024-07-03 11:55:57.149182: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 7077888 totalling 13.50MiB\n",
      "2024-07-03 11:55:57.149205: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 12320768 totalling 11.75MiB\n",
      "2024-07-03 11:55:57.149228: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 12845056 totalling 24.50MiB\n",
      "2024-07-03 11:55:57.149251: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 3 Chunks of size 25690112 totalling 73.50MiB\n",
      "2024-07-03 11:55:57.149274: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 38535168 totalling 36.75MiB\n",
      "2024-07-03 11:55:57.149297: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 4 Chunks of size 51380224 totalling 196.00MiB\n",
      "2024-07-03 11:55:57.149320: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 102760448 totalling 98.00MiB\n",
      "2024-07-03 11:55:57.149344: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 120960000 totalling 115.36MiB\n",
      "2024-07-03 11:55:57.149366: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 205520896 totalling 392.00MiB\n",
      "2024-07-03 11:55:57.149389: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 322560000 totalling 615.23MiB\n",
      "2024-07-03 11:55:57.149415: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 411041792 totalling 392.00MiB\n",
      "2024-07-03 11:55:57.149437: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 536870912 totalling 1.00GiB\n",
      "2024-07-03 11:55:57.149459: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 3 Chunks of size 2580480000 totalling 7.21GiB\n",
      "2024-07-03 11:55:57.149481: I tensorflow/core/common_runtime/bfc_allocator.cc:1078] Sum Total of in-use chunks: 10.17GiB\n",
      "2024-07-03 11:55:57.149503: I tensorflow/core/common_runtime/bfc_allocator.cc:1080] total_region_allocated_bytes_: 15519580160 memory_limit_: 15519580160 available bytes: 0 curr_region_allocation_bytes_: 17179869184\n",
      "2024-07-03 11:55:57.149535: I tensorflow/core/common_runtime/bfc_allocator.cc:1086] Stats: \n",
      "Limit:                     15519580160\n",
      "InUse:                     10922776320\n",
      "MaxInUse:                  14067914752\n",
      "NumAllocs:                      115473\n",
      "MaxAllocSize:               2597257216\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2024-07-03 11:55:57.149636: W tensorflow/core/common_runtime/bfc_allocator.cc:475] **********************************__________*****************__________*********_____***************\n",
      "2024-07-03 11:55:57.149776: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at cudnn_pooling_gpu.cc:153 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[50,64,14,120,120] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[50,64,14,120,120] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/sequential_15/max_pooling3d_34/MaxPool3D/MaxPool3DGrad\n (defined at /usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/optimizer_v2.py:464)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_14820]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/sequential_15/max_pooling3d_34/MaxPool3D/MaxPool3DGrad:\nIn[0] sequential_15/batch_normalization_56/FusedBatchNormV3 (defined at /usr/local/lib/python3.8/dist-packages/keras/layers/normalization/batch_normalization.py:589)\t\nIn[1] sequential_15/max_pooling3d_34/MaxPool3D (defined at /usr/local/lib/python3.8/dist-packages/keras/layers/pooling.py:699)\t\nIn[2] gradient_tape/sequential_15/conv3d_59/Conv3D/Conv3DBackpropInputV2:\n\nOperation defined at: (most recent call last)\n>>>   File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 461, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 450, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 357, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 652, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 359, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n>>>     return super().run_cell(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"/tmp/ipykernel_203/548037436.py\", line 2, in <module>\n>>>     model3=conv_model3.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 816, in train_step\n>>>     self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/optimizer_v2.py\", line 530, in minimize\n>>>     grads_and_vars = self._compute_gradients(\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/optimizer_v2.py\", line 583, in _compute_gradients\n>>>     grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/optimizer_v2.py\", line 464, in _get_gradients\n>>>     grads = tape.gradient(loss, var_list, grad_loss)\n>>> ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_203/548037436.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total Params:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_model3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model3=conv_model3.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n\u001b[0m\u001b[1;32m      3\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[50,64,14,120,120] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/sequential_15/max_pooling3d_34/MaxPool3D/MaxPool3DGrad\n (defined at /usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/optimizer_v2.py:464)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_14820]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node gradient_tape/sequential_15/max_pooling3d_34/MaxPool3D/MaxPool3DGrad:\nIn[0] sequential_15/batch_normalization_56/FusedBatchNormV3 (defined at /usr/local/lib/python3.8/dist-packages/keras/layers/normalization/batch_normalization.py:589)\t\nIn[1] sequential_15/max_pooling3d_34/MaxPool3D (defined at /usr/local/lib/python3.8/dist-packages/keras/layers/pooling.py:699)\t\nIn[2] gradient_tape/sequential_15/conv3d_59/Conv3D/Conv3DBackpropInputV2:\n\nOperation defined at: (most recent call last)\n>>>   File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 461, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 450, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 357, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 652, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 359, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n>>>     return super().run_cell(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"/tmp/ipykernel_203/548037436.py\", line 2, in <module>\n>>>     model3=conv_model3.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 816, in train_step\n>>>     self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/optimizer_v2.py\", line 530, in minimize\n>>>     grads_and_vars = self._compute_gradients(\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/optimizer_v2.py\", line 583, in _compute_gradients\n>>>     grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n>>> \n>>>   File \"/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/optimizer_v2.py\", line 464, in _get_gradients\n>>>     grads = tape.gradient(loss, var_list, grad_loss)\n>>> "
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", conv_model3.count_params())\n",
    "model3=conv_model3.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of frames passed in each video :14\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_61 (Conv3D)          (None, 14, 120, 120, 64)  5248      \n",
      "                                                                 \n",
      " activation_81 (Activation)  (None, 14, 120, 120, 64)  0         \n",
      "                                                                 \n",
      " batch_normalization_59 (Bat  (None, 14, 120, 120, 64)  256      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_37 (MaxPoolin  (None, 7, 60, 60, 64)    0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_62 (Conv3D)          (None, 5, 58, 58, 128)    221312    \n",
      "                                                                 \n",
      " activation_82 (Activation)  (None, 5, 58, 58, 128)    0         \n",
      "                                                                 \n",
      " batch_normalization_60 (Bat  (None, 5, 58, 58, 128)   512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_38 (MaxPoolin  (None, 2, 29, 29, 128)   0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 2, 29, 29, 128)    0         \n",
      "                                                                 \n",
      " conv3d_63 (Conv3D)          (None, 2, 29, 29, 128)    442496    \n",
      "                                                                 \n",
      " activation_83 (Activation)  (None, 2, 29, 29, 128)    0         \n",
      "                                                                 \n",
      " batch_normalization_61 (Bat  (None, 2, 29, 29, 128)   512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_39 (MaxPoolin  (None, 1, 14, 14, 128)   0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 1, 14, 14, 128)    0         \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 25088)             0         \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 512)               12845568  \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,518,469\n",
      "Trainable params: 13,517,829\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_idx,shape_h,shape_w,batch_size,num_epochs = model_vars([2,4,6,8,10,12,14,16,18,20,22,24,26,28],120,120,20,15)\n",
    "conv_model4=Conv3DModel3(frames_to_sample=len(img_idx),image_height=shape_h,image_width=shape_w)\n",
    "conv_model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch: 34\n",
      "validation_steps: 5\n"
     ]
    }
   ],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print(\"steps_per_epoch:\", steps_per_epoch)\n",
    "print(\"validation_steps:\", validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 13518469\n",
      "Source path =  /home/datasets/Project_data/train ; batch size = 20\n",
      "Epoch 1/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 11.4049 - categorical_accuracy: 0.3294Source path =  /home/datasets/Project_data/val ; batch size = 20\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.82232\n",
      "34/34 [==============================] - 135s 4s/step - loss: 11.4049 - categorical_accuracy: 0.3294 - val_loss: 16.9919 - val_categorical_accuracy: 0.2700 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 4.0425 - categorical_accuracy: 0.4912\n",
      "Epoch 00002: val_loss did not improve from 1.82232\n",
      "34/34 [==============================] - 134s 4s/step - loss: 4.0425 - categorical_accuracy: 0.4912 - val_loss: 4.1512 - val_categorical_accuracy: 0.2900 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.9614 - categorical_accuracy: 0.4941\n",
      "Epoch 00003: val_loss did not improve from 1.82232\n",
      "34/34 [==============================] - 135s 4s/step - loss: 1.9614 - categorical_accuracy: 0.4941 - val_loss: 3.3571 - val_categorical_accuracy: 0.3100 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.5425 - categorical_accuracy: 0.5147\n",
      "Epoch 00004: val_loss did not improve from 1.82232\n",
      "34/34 [==============================] - 139s 4s/step - loss: 1.5425 - categorical_accuracy: 0.5147 - val_loss: 7.1083 - val_categorical_accuracy: 0.2300 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.4879 - categorical_accuracy: 0.5485\n",
      "Epoch 00005: val_loss did not improve from 1.82232\n",
      "34/34 [==============================] - 139s 4s/step - loss: 1.4879 - categorical_accuracy: 0.5485 - val_loss: 6.1899 - val_categorical_accuracy: 0.2600 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.1687 - categorical_accuracy: 0.5853\n",
      "Epoch 00006: val_loss did not improve from 1.82232\n",
      "34/34 [==============================] - 139s 4s/step - loss: 1.1687 - categorical_accuracy: 0.5853 - val_loss: 7.5843 - val_categorical_accuracy: 0.2600 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0225 - categorical_accuracy: 0.6412\n",
      "Epoch 00007: val_loss did not improve from 1.82232\n",
      "34/34 [==============================] - 138s 4s/step - loss: 1.0225 - categorical_accuracy: 0.6412 - val_loss: 7.9268 - val_categorical_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.8967 - categorical_accuracy: 0.6529\n",
      "Epoch 00008: val_loss did not improve from 1.82232\n",
      "34/34 [==============================] - 138s 4s/step - loss: 0.8967 - categorical_accuracy: 0.6529 - val_loss: 5.5753 - val_categorical_accuracy: 0.2300 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.9870 - categorical_accuracy: 0.6426\n",
      "Epoch 00009: val_loss did not improve from 1.82232\n",
      "34/34 [==============================] - 138s 4s/step - loss: 0.9870 - categorical_accuracy: 0.6426 - val_loss: 6.2488 - val_categorical_accuracy: 0.3300 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.9381 - categorical_accuracy: 0.6456\n",
      "Epoch 00010: val_loss did not improve from 1.82232\n",
      "34/34 [==============================] - 139s 4s/step - loss: 0.9381 - categorical_accuracy: 0.6456 - val_loss: 7.4940 - val_categorical_accuracy: 0.3200 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.8805 - categorical_accuracy: 0.6735\n",
      "Epoch 00011: val_loss did not improve from 1.82232\n",
      "34/34 [==============================] - 137s 4s/step - loss: 0.8805 - categorical_accuracy: 0.6735 - val_loss: 6.0053 - val_categorical_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 12/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.9749 - categorical_accuracy: 0.6603\n",
      "Epoch 00012: val_loss did not improve from 1.82232\n",
      "34/34 [==============================] - 131s 4s/step - loss: 0.9749 - categorical_accuracy: 0.6603 - val_loss: 2.0407 - val_categorical_accuracy: 0.4500 - lr: 0.0010\n",
      "Epoch 13/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.9129 - categorical_accuracy: 0.6500\n",
      "Epoch 00013: val_loss did not improve from 1.82232\n",
      "34/34 [==============================] - 134s 4s/step - loss: 0.9129 - categorical_accuracy: 0.6500 - val_loss: 4.4478 - val_categorical_accuracy: 0.3600 - lr: 0.0010\n",
      "Epoch 14/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0803 - categorical_accuracy: 0.6500\n",
      "Epoch 00014: val_loss did not improve from 1.82232\n",
      "34/34 [==============================] - 132s 4s/step - loss: 1.0803 - categorical_accuracy: 0.6500 - val_loss: 2.9012 - val_categorical_accuracy: 0.5800 - lr: 0.0010\n",
      "Epoch 15/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.8489 - categorical_accuracy: 0.6824\n",
      "Epoch 00015: val_loss did not improve from 1.82232\n",
      "34/34 [==============================] - 132s 4s/step - loss: 0.8489 - categorical_accuracy: 0.6824 - val_loss: 3.3478 - val_categorical_accuracy: 0.4100 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", conv_model3.count_params())\n",
    "model4=conv_model3.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv3DModel5(frames_to_sample,image_height,image_width):\n",
    "    \n",
    "    Input_shape=(frames_to_sample,image_height,image_width,3)\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(16, (3,3,3), padding='same', input_shape=Input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "\n",
    "    model.add(Conv3D(32, (3, 3,3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "\n",
    "    model.add(Conv3D(64, (3, 3,3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "\n",
    "    model.add(Conv3D(128, (3, 3,3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(5,activation='softmax'))\n",
    "    \n",
    "    optimiser = 'adam'\n",
    "    model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of frames passed in each video :20\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_40 (Conv3D)          (None, 20, 120, 120, 16)  1312      \n",
      "                                                                 \n",
      " activation_36 (Activation)  (None, 20, 120, 120, 16)  0         \n",
      "                                                                 \n",
      " batch_normalization_36 (Bat  (None, 20, 120, 120, 16)  64       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_32 (MaxPoolin  (None, 10, 60, 60, 16)   0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_41 (Conv3D)          (None, 10, 60, 60, 32)    13856     \n",
      "                                                                 \n",
      " activation_37 (Activation)  (None, 10, 60, 60, 32)    0         \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 10, 60, 60, 32)   128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_33 (MaxPoolin  (None, 5, 30, 30, 32)    0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_42 (Conv3D)          (None, 5, 30, 30, 64)     55360     \n",
      "                                                                 \n",
      " activation_38 (Activation)  (None, 5, 30, 30, 64)     0         \n",
      "                                                                 \n",
      " batch_normalization_38 (Bat  (None, 5, 30, 30, 64)    256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_34 (MaxPoolin  (None, 2, 15, 15, 64)    0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_43 (Conv3D)          (None, 2, 15, 15, 128)    221312    \n",
      "                                                                 \n",
      " activation_39 (Activation)  (None, 2, 15, 15, 128)    0         \n",
      "                                                                 \n",
      " batch_normalization_39 (Bat  (None, 2, 15, 15, 128)   512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_35 (MaxPoolin  (None, 1, 7, 7, 128)     0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                401472    \n",
      "                                                                 \n",
      " batch_normalization_40 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 694,853\n",
      "Trainable params: 694,245\n",
      "Non-trainable params: 608\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_idx,shape_h,shape_w,batch_size,num_epochs = model_vars([2,4,6,8,10,11,12,14,15,16,18,20,21,22,24,25,26,27,28,29],120,120,20,15)\n",
    "conv_model5=Conv3DModel5(frames_to_sample=len(img_idx),image_height=shape_h,image_width=shape_w)\n",
    "conv_model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch: 34\n",
      "validation_steps: 5\n"
     ]
    }
   ],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print(\"steps_per_epoch:\", steps_per_epoch)\n",
    "print(\"validation_steps:\", validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 694853\n",
      "Source path =  /home/datasets/Project_data/train ; batch size = 20\n",
      "Epoch 1/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.1387 - categorical_accuracy: 0.5338Source path =  /home/datasets/Project_data/val ; batch size = 20\n",
      "\n",
      "Epoch 00001: val_loss improved from 2.40356 to 2.25245, saving model to model_init_2024-07-0313_10_35.017888/model-00001-1.13873-0.53382-2.25245-0.18000.h5\n",
      "34/34 [==============================] - 209s 6s/step - loss: 1.1387 - categorical_accuracy: 0.5338 - val_loss: 2.2525 - val_categorical_accuracy: 0.1800 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.7148 - categorical_accuracy: 0.6868\n",
      "Epoch 00002: val_loss did not improve from 2.25245\n",
      "34/34 [==============================] - 215s 7s/step - loss: 0.7148 - categorical_accuracy: 0.6868 - val_loss: 4.2636 - val_categorical_accuracy: 0.2300 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.5356 - categorical_accuracy: 0.7735\n",
      "Epoch 00003: val_loss did not improve from 2.25245\n",
      "34/34 [==============================] - 199s 6s/step - loss: 0.5356 - categorical_accuracy: 0.7735 - val_loss: 6.0919 - val_categorical_accuracy: 0.1600 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.4242 - categorical_accuracy: 0.8206\n",
      "Epoch 00004: val_loss did not improve from 2.25245\n",
      "34/34 [==============================] - 204s 6s/step - loss: 0.4242 - categorical_accuracy: 0.8206 - val_loss: 6.0101 - val_categorical_accuracy: 0.1900 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3360 - categorical_accuracy: 0.8735\n",
      "Epoch 00005: val_loss did not improve from 2.25245\n",
      "34/34 [==============================] - 209s 6s/step - loss: 0.3360 - categorical_accuracy: 0.8735 - val_loss: 3.2683 - val_categorical_accuracy: 0.2300 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2238 - categorical_accuracy: 0.9250\n",
      "Epoch 00006: val_loss did not improve from 2.25245\n",
      "34/34 [==============================] - 211s 6s/step - loss: 0.2238 - categorical_accuracy: 0.9250 - val_loss: 4.9417 - val_categorical_accuracy: 0.2200 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2110 - categorical_accuracy: 0.9294\n",
      "Epoch 00007: val_loss did not improve from 2.25245\n",
      "34/34 [==============================] - 210s 6s/step - loss: 0.2110 - categorical_accuracy: 0.9294 - val_loss: 3.5955 - val_categorical_accuracy: 0.2800 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1703 - categorical_accuracy: 0.9309\n",
      "Epoch 00008: val_loss did not improve from 2.25245\n",
      "34/34 [==============================] - 211s 6s/step - loss: 0.1703 - categorical_accuracy: 0.9309 - val_loss: 3.4204 - val_categorical_accuracy: 0.2900 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1390 - categorical_accuracy: 0.9515\n",
      "Epoch 00009: val_loss did not improve from 2.25245\n",
      "34/34 [==============================] - 209s 6s/step - loss: 0.1390 - categorical_accuracy: 0.9515 - val_loss: 2.8864 - val_categorical_accuracy: 0.2700 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1285 - categorical_accuracy: 0.9588\n",
      "Epoch 00010: val_loss did not improve from 2.25245\n",
      "34/34 [==============================] - 208s 6s/step - loss: 0.1285 - categorical_accuracy: 0.9588 - val_loss: 2.2798 - val_categorical_accuracy: 0.3200 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1074 - categorical_accuracy: 0.9588\n",
      "Epoch 00011: val_loss improved from 2.25245 to 1.48599, saving model to model_init_2024-07-0313_10_35.017888/model-00011-0.10742-0.95882-1.48599-0.44000.h5\n",
      "34/34 [==============================] - 211s 6s/step - loss: 0.1074 - categorical_accuracy: 0.9588 - val_loss: 1.4860 - val_categorical_accuracy: 0.4400 - lr: 0.0010\n",
      "Epoch 12/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0927 - categorical_accuracy: 0.9647\n",
      "Epoch 00012: val_loss did not improve from 1.48599\n",
      "34/34 [==============================] - 208s 6s/step - loss: 0.0927 - categorical_accuracy: 0.9647 - val_loss: 1.8181 - val_categorical_accuracy: 0.4300 - lr: 0.0010\n",
      "Epoch 13/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0707 - categorical_accuracy: 0.9691\n",
      "Epoch 00013: val_loss improved from 1.48599 to 1.42677, saving model to model_init_2024-07-0313_10_35.017888/model-00013-0.07073-0.96912-1.42677-0.55000.h5\n",
      "34/34 [==============================] - 206s 6s/step - loss: 0.0707 - categorical_accuracy: 0.9691 - val_loss: 1.4268 - val_categorical_accuracy: 0.5500 - lr: 0.0010\n",
      "Epoch 14/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0954 - categorical_accuracy: 0.9529\n",
      "Epoch 00014: val_loss did not improve from 1.42677\n",
      "34/34 [==============================] - 211s 6s/step - loss: 0.0954 - categorical_accuracy: 0.9529 - val_loss: 1.9597 - val_categorical_accuracy: 0.5400 - lr: 0.0010\n",
      "Epoch 15/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0697 - categorical_accuracy: 0.9721\n",
      "Epoch 00015: val_loss improved from 1.42677 to 0.86642, saving model to model_init_2024-07-0313_10_35.017888/model-00015-0.06970-0.97206-0.86642-0.70000.h5\n",
      "34/34 [==============================] - 205s 6s/step - loss: 0.0697 - categorical_accuracy: 0.9721 - val_loss: 0.8664 - val_categorical_accuracy: 0.7000 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", conv_model5.count_params())\n",
    "model5=conv_model5.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv3DModel6(frames_to_sample,image_height,image_width):\n",
    "    \n",
    "    Input_shape=(frames_to_sample,image_height,image_width,3)\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(16, (3,3,3), padding='same', input_shape=Input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "\n",
    "    model.add(Conv3D(32, (3, 3,3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "\n",
    "    model.add(Conv3D(64, (3, 3,3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "\n",
    "    model.add(Conv3D(128, (3, 3,3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv3D(128, (3, 3,3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(5,activation='softmax'))\n",
    "    \n",
    "    optimiser = 'adam'\n",
    "    model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of frames passed in each video :16\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_43 (Conv3D)          (None, 16, 120, 120, 16)  1312      \n",
      "                                                                 \n",
      " activation_45 (Activation)  (None, 16, 120, 120, 16)  0         \n",
      "                                                                 \n",
      " batch_normalization_45 (Bat  (None, 16, 120, 120, 16)  64       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_38 (MaxPoolin  (None, 8, 60, 60, 16)    0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_44 (Conv3D)          (None, 8, 60, 60, 32)     13856     \n",
      "                                                                 \n",
      " activation_46 (Activation)  (None, 8, 60, 60, 32)     0         \n",
      "                                                                 \n",
      " batch_normalization_46 (Bat  (None, 8, 60, 60, 32)    128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_39 (MaxPoolin  (None, 4, 30, 30, 32)    0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_45 (Conv3D)          (None, 4, 30, 30, 64)     55360     \n",
      "                                                                 \n",
      " activation_47 (Activation)  (None, 4, 30, 30, 64)     0         \n",
      "                                                                 \n",
      " batch_normalization_47 (Bat  (None, 4, 30, 30, 64)    256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_40 (MaxPoolin  (None, 2, 15, 15, 64)    0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_46 (Conv3D)          (None, 2, 15, 15, 128)    221312    \n",
      "                                                                 \n",
      " activation_48 (Activation)  (None, 2, 15, 15, 128)    0         \n",
      "                                                                 \n",
      " batch_normalization_48 (Bat  (None, 2, 15, 15, 128)   512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv3d_47 (Conv3D)          (None, 2, 15, 15, 128)    442496    \n",
      "                                                                 \n",
      " activation_49 (Activation)  (None, 2, 15, 15, 128)    0         \n",
      "                                                                 \n",
      " batch_normalization_49 (Bat  (None, 2, 15, 15, 128)   512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_41 (MaxPoolin  (None, 1, 7, 7, 128)     0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                401472    \n",
      "                                                                 \n",
      " batch_normalization_50 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,137,861\n",
      "Trainable params: 1,136,997\n",
      "Non-trainable params: 864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_idx,shape_h,shape_w,batch_size,num_epochs = model_vars([2,4,6,8,10,12,14,16,17,18,20,22,24,25,26,28],120,120,20,15)\n",
    "conv_model6=Conv3DModel6(frames_to_sample=len(img_idx),image_height=shape_h,image_width=shape_w)\n",
    "conv_model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch: 34\n",
      "validation_steps: 5\n"
     ]
    }
   ],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print(\"steps_per_epoch:\", steps_per_epoch)\n",
    "print(\"validation_steps:\", validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 1137861\n",
      "Source path =  /home/datasets/Project_data/train ; batch size = 20\n",
      "Epoch 1/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.2023 - categorical_accuracy: 0.5103Source path =  /home/datasets/Project_data/val ; batch size = 20\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.79612, saving model to model_init_2024-07-0405_10_51.681471/model-00001-1.20229-0.51029-1.79612-0.32000.h5\n",
      "34/34 [==============================] - 206s 6s/step - loss: 1.2023 - categorical_accuracy: 0.5103 - val_loss: 1.7961 - val_categorical_accuracy: 0.3200 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.7502 - categorical_accuracy: 0.6897\n",
      "Epoch 00002: val_loss did not improve from 1.79612\n",
      "34/34 [==============================] - 160s 5s/step - loss: 0.7502 - categorical_accuracy: 0.6897 - val_loss: 1.9811 - val_categorical_accuracy: 0.2200 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.5750 - categorical_accuracy: 0.7676\n",
      "Epoch 00003: val_loss did not improve from 1.79612\n",
      "34/34 [==============================] - 154s 5s/step - loss: 0.5750 - categorical_accuracy: 0.7676 - val_loss: 2.6779 - val_categorical_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.4216 - categorical_accuracy: 0.8441\n",
      "Epoch 00004: val_loss did not improve from 1.79612\n",
      "34/34 [==============================] - 147s 4s/step - loss: 0.4216 - categorical_accuracy: 0.8441 - val_loss: 3.2881 - val_categorical_accuracy: 0.2500 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3791 - categorical_accuracy: 0.8456\n",
      "Epoch 00005: val_loss did not improve from 1.79612\n",
      "34/34 [==============================] - 148s 4s/step - loss: 0.3791 - categorical_accuracy: 0.8456 - val_loss: 2.3364 - val_categorical_accuracy: 0.2400 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3143 - categorical_accuracy: 0.8809\n",
      "Epoch 00006: val_loss did not improve from 1.79612\n",
      "34/34 [==============================] - 152s 5s/step - loss: 0.3143 - categorical_accuracy: 0.8809 - val_loss: 4.6057 - val_categorical_accuracy: 0.2100 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2008 - categorical_accuracy: 0.9441\n",
      "Epoch 00007: val_loss did not improve from 1.79612\n",
      "34/34 [==============================] - 154s 5s/step - loss: 0.2008 - categorical_accuracy: 0.9441 - val_loss: 3.0952 - val_categorical_accuracy: 0.2200 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1750 - categorical_accuracy: 0.9412\n",
      "Epoch 00008: val_loss did not improve from 1.79612\n",
      "34/34 [==============================] - 151s 5s/step - loss: 0.1750 - categorical_accuracy: 0.9412 - val_loss: 2.5565 - val_categorical_accuracy: 0.2900 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1291 - categorical_accuracy: 0.9456\n",
      "Epoch 00009: val_loss did not improve from 1.79612\n",
      "34/34 [==============================] - 151s 5s/step - loss: 0.1291 - categorical_accuracy: 0.9456 - val_loss: 2.8343 - val_categorical_accuracy: 0.2600 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1063 - categorical_accuracy: 0.9618\n",
      "Epoch 00010: val_loss did not improve from 1.79612\n",
      "34/34 [==============================] - 154s 5s/step - loss: 0.1063 - categorical_accuracy: 0.9618 - val_loss: 2.1888 - val_categorical_accuracy: 0.3400 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1087 - categorical_accuracy: 0.9647\n",
      "Epoch 00011: val_loss did not improve from 1.79612\n",
      "34/34 [==============================] - 152s 5s/step - loss: 0.1087 - categorical_accuracy: 0.9647 - val_loss: 2.2213 - val_categorical_accuracy: 0.4200 - lr: 0.0010\n",
      "Epoch 12/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0766 - categorical_accuracy: 0.9691\n",
      "Epoch 00012: val_loss improved from 1.79612 to 1.74636, saving model to model_init_2024-07-0405_10_51.681471/model-00012-0.07655-0.96912-1.74636-0.53000.h5\n",
      "34/34 [==============================] - 154s 5s/step - loss: 0.0766 - categorical_accuracy: 0.9691 - val_loss: 1.7464 - val_categorical_accuracy: 0.5300 - lr: 1.0000e-04\n",
      "Epoch 13/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0700 - categorical_accuracy: 0.9706\n",
      "Epoch 00013: val_loss improved from 1.74636 to 1.48783, saving model to model_init_2024-07-0405_10_51.681471/model-00013-0.07001-0.97059-1.48783-0.50000.h5\n",
      "34/34 [==============================] - 153s 5s/step - loss: 0.0700 - categorical_accuracy: 0.9706 - val_loss: 1.4878 - val_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 14/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0621 - categorical_accuracy: 0.9735\n",
      "Epoch 00014: val_loss did not improve from 1.48783\n",
      "34/34 [==============================] - 152s 5s/step - loss: 0.0621 - categorical_accuracy: 0.9735 - val_loss: 1.5161 - val_categorical_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 15/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0476 - categorical_accuracy: 0.9735\n",
      "Epoch 00015: val_loss improved from 1.48783 to 1.03447, saving model to model_init_2024-07-0405_10_51.681471/model-00015-0.04762-0.97353-1.03447-0.59000.h5\n",
      "34/34 [==============================] - 151s 5s/step - loss: 0.0476 - categorical_accuracy: 0.9735 - val_loss: 1.0345 - val_categorical_accuracy: 0.5900 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", conv_model6.count_params())\n",
    "model6=conv_model6.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv3DModel7(frames_to_sample,image_height,image_width):\n",
    "    \n",
    "    Input_shape=(frames_to_sample,image_height,image_width,3)\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(16, (3,3,3), padding='same', input_shape=Input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv3D(32, (3, 3,3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv3D(64, (3, 3,3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv3D(128, (3, 3,3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv3D(128, (3, 3,3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(5,activation='softmax'))\n",
    "    \n",
    "    optimiser = 'adam'\n",
    "    model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of frames passed in each video :15\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_5 (Conv3D)           (None, 15, 120, 120, 16)  1312      \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 15, 120, 120, 16)  0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 15, 120, 120, 16)  64       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 15, 120, 120, 16)  0         \n",
      "                                                                 \n",
      " conv3d_6 (Conv3D)           (None, 15, 120, 120, 32)  13856     \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 15, 120, 120, 32)  0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 15, 120, 120, 32)  128      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling3d_4 (MaxPooling  (None, 7, 60, 60, 32)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 7, 60, 60, 32)     0         \n",
      "                                                                 \n",
      " conv3d_7 (Conv3D)           (None, 7, 60, 60, 64)     55360     \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 7, 60, 60, 64)     0         \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 7, 60, 60, 64)    256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling3d_5 (MaxPooling  (None, 3, 30, 30, 64)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 3, 30, 30, 64)     0         \n",
      "                                                                 \n",
      " conv3d_8 (Conv3D)           (None, 3, 30, 30, 128)    221312    \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 3, 30, 30, 128)    0         \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 3, 30, 30, 128)   512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 3, 30, 30, 128)    0         \n",
      "                                                                 \n",
      " conv3d_9 (Conv3D)           (None, 3, 30, 30, 128)    442496    \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 3, 30, 30, 128)    0         \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 3, 30, 30, 128)   512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling3d_6 (MaxPooling  (None, 1, 15, 15, 128)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 1, 15, 15, 128)    0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 28800)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1843264   \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,579,653\n",
      "Trainable params: 2,578,789\n",
      "Non-trainable params: 864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_idx,shape_h,shape_w,batch_size,num_epochs = model_vars(list(range(0,30,2)),120,120,20,15)\n",
    "conv_model7=Conv3DModel7(frames_to_sample=len(img_idx),image_height=shape_h,image_width=shape_w)\n",
    "conv_model7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch: 34\n",
      "validation_steps: 5\n"
     ]
    }
   ],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print(\"steps_per_epoch:\", steps_per_epoch)\n",
    "print(\"validation_steps:\", validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 2579653\n",
      "Source path =  /home/datasets/Project_data/train ; batch size = 20\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-05 10:30:53.091703: I tensorflow/stream_executor/cuda/cuda_dnn.cc:377] Loaded cuDNN version 8302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - ETA: 0s - loss: 1.3514 - categorical_accuracy: 0.4162Source path =  /home/datasets/Project_data/val ; batch size = 20\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.41231, saving model to model_init_2024-07-0510_28_50.488551/model-00001-1.35141-0.41618-2.41231-0.16000.h5\n",
      "34/34 [==============================] - 160s 5s/step - loss: 1.3514 - categorical_accuracy: 0.4162 - val_loss: 2.4123 - val_categorical_accuracy: 0.1600 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.9349 - categorical_accuracy: 0.6265\n",
      "Epoch 00002: val_loss did not improve from 2.41231\n",
      "34/34 [==============================] - 154s 5s/step - loss: 0.9349 - categorical_accuracy: 0.6265 - val_loss: 2.4267 - val_categorical_accuracy: 0.1900 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.7948 - categorical_accuracy: 0.6632\n",
      "Epoch 00003: val_loss did not improve from 2.41231\n",
      "34/34 [==============================] - 152s 5s/step - loss: 0.7948 - categorical_accuracy: 0.6632 - val_loss: 2.7068 - val_categorical_accuracy: 0.1600 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6509 - categorical_accuracy: 0.7221\n",
      "Epoch 00004: val_loss did not improve from 2.41231\n",
      "34/34 [==============================] - 166s 5s/step - loss: 0.6509 - categorical_accuracy: 0.7221 - val_loss: 3.5089 - val_categorical_accuracy: 0.2100 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.5508 - categorical_accuracy: 0.7838\n",
      "Epoch 00005: val_loss improved from 2.41231 to 2.19891, saving model to model_init_2024-07-0510_28_50.488551/model-00005-0.55080-0.78382-2.19891-0.20000.h5\n",
      "34/34 [==============================] - 160s 5s/step - loss: 0.5508 - categorical_accuracy: 0.7838 - val_loss: 2.1989 - val_categorical_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.4383 - categorical_accuracy: 0.8294\n",
      "Epoch 00006: val_loss did not improve from 2.19891\n",
      "34/34 [==============================] - 149s 5s/step - loss: 0.4383 - categorical_accuracy: 0.8294 - val_loss: 3.6414 - val_categorical_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3338 - categorical_accuracy: 0.8676\n",
      "Epoch 00007: val_loss did not improve from 2.19891\n",
      "34/34 [==============================] - 157s 5s/step - loss: 0.3338 - categorical_accuracy: 0.8676 - val_loss: 2.9939 - val_categorical_accuracy: 0.2200 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2910 - categorical_accuracy: 0.9044\n",
      "Epoch 00008: val_loss did not improve from 2.19891\n",
      "34/34 [==============================] - 157s 5s/step - loss: 0.2910 - categorical_accuracy: 0.9044 - val_loss: 3.2736 - val_categorical_accuracy: 0.2200 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2549 - categorical_accuracy: 0.9235\n",
      "Epoch 00009: val_loss did not improve from 2.19891\n",
      "34/34 [==============================] - 160s 5s/step - loss: 0.2549 - categorical_accuracy: 0.9235 - val_loss: 4.0512 - val_categorical_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2204 - categorical_accuracy: 0.9235\n",
      "Epoch 00010: val_loss did not improve from 2.19891\n",
      "34/34 [==============================] - 171s 5s/step - loss: 0.2204 - categorical_accuracy: 0.9235 - val_loss: 4.2889 - val_categorical_accuracy: 0.2300 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1759 - categorical_accuracy: 0.9456\n",
      "Epoch 00011: val_loss did not improve from 2.19891\n",
      "34/34 [==============================] - 155s 5s/step - loss: 0.1759 - categorical_accuracy: 0.9456 - val_loss: 3.8371 - val_categorical_accuracy: 0.2700 - lr: 0.0010\n",
      "Epoch 12/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1597 - categorical_accuracy: 0.9324\n",
      "Epoch 00012: val_loss did not improve from 2.19891\n",
      "34/34 [==============================] - 159s 5s/step - loss: 0.1597 - categorical_accuracy: 0.9324 - val_loss: 2.9797 - val_categorical_accuracy: 0.3000 - lr: 0.0010\n",
      "Epoch 13/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1298 - categorical_accuracy: 0.9676\n",
      "Epoch 00013: val_loss did not improve from 2.19891\n",
      "34/34 [==============================] - 151s 5s/step - loss: 0.1298 - categorical_accuracy: 0.9676 - val_loss: 3.8111 - val_categorical_accuracy: 0.2300 - lr: 0.0010\n",
      "Epoch 14/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1152 - categorical_accuracy: 0.9618\n",
      "Epoch 00014: val_loss did not improve from 2.19891\n",
      "34/34 [==============================] - 151s 5s/step - loss: 0.1152 - categorical_accuracy: 0.9618 - val_loss: 3.4219 - val_categorical_accuracy: 0.2700 - lr: 0.0010\n",
      "Epoch 15/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1110 - categorical_accuracy: 0.9603\n",
      "Epoch 00015: val_loss did not improve from 2.19891\n",
      "34/34 [==============================] - 149s 5s/step - loss: 0.1110 - categorical_accuracy: 0.9603 - val_loss: 2.9073 - val_categorical_accuracy: 0.2700 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", conv_model7.count_params())\n",
    "model7=conv_model7.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "def Conv3DModel8(frames_to_sample,image_height,image_width):\n",
    "    \n",
    "    Input_shape=(frames_to_sample,image_height,image_width,3)\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(16, (3,3,3), padding='same', input_shape=Input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "\n",
    "    model.add(Conv3D(32, (3, 3,3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "\n",
    "    model.add(Conv3D(64, (3, 3,3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "\n",
    "    model.add(Conv3D(128, (3, 3,3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv3D(128, (3, 3,3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu',kernel_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(5,activation='softmax'))\n",
    "    \n",
    "    optimiser = 'adam'\n",
    "    model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of frames passed in each video :16\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_40 (Conv3D)          (None, 16, 120, 120, 16)  1312      \n",
      "                                                                 \n",
      " activation_40 (Activation)  (None, 16, 120, 120, 16)  0         \n",
      "                                                                 \n",
      " batch_normalization_43 (Bat  (None, 16, 120, 120, 16)  64       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_31 (MaxPoolin  (None, 8, 60, 60, 16)    0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_41 (Conv3D)          (None, 8, 60, 60, 32)     13856     \n",
      "                                                                 \n",
      " activation_41 (Activation)  (None, 8, 60, 60, 32)     0         \n",
      "                                                                 \n",
      " batch_normalization_44 (Bat  (None, 8, 60, 60, 32)    128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_32 (MaxPoolin  (None, 4, 30, 30, 32)    0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_42 (Conv3D)          (None, 4, 30, 30, 64)     55360     \n",
      "                                                                 \n",
      " activation_42 (Activation)  (None, 4, 30, 30, 64)     0         \n",
      "                                                                 \n",
      " batch_normalization_45 (Bat  (None, 4, 30, 30, 64)    256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_33 (MaxPoolin  (None, 2, 15, 15, 64)    0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_43 (Conv3D)          (None, 2, 15, 15, 128)    221312    \n",
      "                                                                 \n",
      " activation_43 (Activation)  (None, 2, 15, 15, 128)    0         \n",
      "                                                                 \n",
      " batch_normalization_46 (Bat  (None, 2, 15, 15, 128)   512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv3d_44 (Conv3D)          (None, 2, 15, 15, 128)    442496    \n",
      "                                                                 \n",
      " activation_44 (Activation)  (None, 2, 15, 15, 128)    0         \n",
      "                                                                 \n",
      " batch_normalization_47 (Bat  (None, 2, 15, 15, 128)   512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_34 (MaxPoolin  (None, 1, 7, 7, 128)     0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               802944    \n",
      "                                                                 \n",
      " batch_normalization_48 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,539,909\n",
      "Trainable params: 1,538,917\n",
      "Non-trainable params: 992\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_idx,shape_h,shape_w,batch_size,num_epochs = model_vars([2,4,6,8,10,12,14,16,17,18,20,22,24,25,26,28],120,120,20,15)\n",
    "conv_model8=Conv3DModel8(frames_to_sample=len(img_idx),image_height=shape_h,image_width=shape_w)\n",
    "conv_model8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch: 34\n",
      "validation_steps: 5\n"
     ]
    }
   ],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print(\"steps_per_epoch:\", steps_per_epoch)\n",
    "print(\"validation_steps:\", validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 1539909\n",
      "Source path =  /home/datasets/Project_data/train ; batch size = 20\n",
      "Epoch 1/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 3.6199 - categorical_accuracy: 0.4868Source path =  /home/datasets/Project_data/val ; batch size = 20\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 2.19891\n",
      "34/34 [==============================] - 167s 5s/step - loss: 3.6199 - categorical_accuracy: 0.4868 - val_loss: 4.4663 - val_categorical_accuracy: 0.2400 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 2.6279 - categorical_accuracy: 0.7353\n",
      "Epoch 00002: val_loss did not improve from 2.19891\n",
      "34/34 [==============================] - 172s 5s/step - loss: 2.6279 - categorical_accuracy: 0.7353 - val_loss: 4.6851 - val_categorical_accuracy: 0.1700 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 2.0226 - categorical_accuracy: 0.7941\n",
      "Epoch 00003: val_loss did not improve from 2.19891\n",
      "34/34 [==============================] - 162s 5s/step - loss: 2.0226 - categorical_accuracy: 0.7941 - val_loss: 3.5973 - val_categorical_accuracy: 0.3200 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.6466 - categorical_accuracy: 0.8088\n",
      "Epoch 00004: val_loss did not improve from 2.19891\n",
      "34/34 [==============================] - 154s 5s/step - loss: 1.6466 - categorical_accuracy: 0.8088 - val_loss: 5.0189 - val_categorical_accuracy: 0.2000 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.2819 - categorical_accuracy: 0.8794\n",
      "Epoch 00005: val_loss did not improve from 2.19891\n",
      "34/34 [==============================] - 154s 5s/step - loss: 1.2819 - categorical_accuracy: 0.8794 - val_loss: 3.3284 - val_categorical_accuracy: 0.1800 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0836 - categorical_accuracy: 0.8750\n",
      "Epoch 00006: val_loss did not improve from 2.19891\n",
      "34/34 [==============================] - 152s 5s/step - loss: 1.0836 - categorical_accuracy: 0.8750 - val_loss: 2.9662 - val_categorical_accuracy: 0.2300 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.9349 - categorical_accuracy: 0.8926\n",
      "Epoch 00007: val_loss did not improve from 2.19891\n",
      "34/34 [==============================] - 153s 5s/step - loss: 0.9349 - categorical_accuracy: 0.8926 - val_loss: 2.5005 - val_categorical_accuracy: 0.2400 - lr: 0.0010\n",
      "Epoch 8/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.7734 - categorical_accuracy: 0.9074\n",
      "Epoch 00008: val_loss did not improve from 2.19891\n",
      "34/34 [==============================] - 155s 5s/step - loss: 0.7734 - categorical_accuracy: 0.9074 - val_loss: 2.2271 - val_categorical_accuracy: 0.2900 - lr: 0.0010\n",
      "Epoch 9/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6210 - categorical_accuracy: 0.9338\n",
      "Epoch 00009: val_loss did not improve from 2.19891\n",
      "34/34 [==============================] - 166s 5s/step - loss: 0.6210 - categorical_accuracy: 0.9338 - val_loss: 2.2658 - val_categorical_accuracy: 0.3400 - lr: 0.0010\n",
      "Epoch 10/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.5425 - categorical_accuracy: 0.9412\n",
      "Epoch 00010: val_loss improved from 2.19891 to 1.86156, saving model to model_init_2024-07-0510_28_50.488551/model-00010-0.54247-0.94118-1.86156-0.37000.h5\n",
      "34/34 [==============================] - 161s 5s/step - loss: 0.5425 - categorical_accuracy: 0.9412 - val_loss: 1.8616 - val_categorical_accuracy: 0.3700 - lr: 0.0010\n",
      "Epoch 11/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.4997 - categorical_accuracy: 0.9382\n",
      "Epoch 00011: val_loss did not improve from 1.86156\n",
      "34/34 [==============================] - 157s 5s/step - loss: 0.4997 - categorical_accuracy: 0.9382 - val_loss: 2.5108 - val_categorical_accuracy: 0.3400 - lr: 0.0010\n",
      "Epoch 12/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.4253 - categorical_accuracy: 0.9574\n",
      "Epoch 00012: val_loss improved from 1.86156 to 1.60277, saving model to model_init_2024-07-0510_28_50.488551/model-00012-0.42525-0.95735-1.60277-0.51000.h5\n",
      "34/34 [==============================] - 151s 5s/step - loss: 0.4253 - categorical_accuracy: 0.9574 - val_loss: 1.6028 - val_categorical_accuracy: 0.5100 - lr: 0.0010\n",
      "Epoch 13/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3794 - categorical_accuracy: 0.9603\n",
      "Epoch 00013: val_loss did not improve from 1.60277\n",
      "34/34 [==============================] - 158s 5s/step - loss: 0.3794 - categorical_accuracy: 0.9603 - val_loss: 2.2283 - val_categorical_accuracy: 0.4800 - lr: 0.0010\n",
      "Epoch 14/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3527 - categorical_accuracy: 0.9574\n",
      "Epoch 00014: val_loss did not improve from 1.60277\n",
      "34/34 [==============================] - 157s 5s/step - loss: 0.3527 - categorical_accuracy: 0.9574 - val_loss: 1.6177 - val_categorical_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 15/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3292 - categorical_accuracy: 0.9603\n",
      "Epoch 00015: val_loss improved from 1.60277 to 1.16602, saving model to model_init_2024-07-0510_28_50.488551/model-00015-0.32925-0.96029-1.16602-0.70000.h5\n",
      "34/34 [==============================] - 156s 5s/step - loss: 0.3292 - categorical_accuracy: 0.9603 - val_loss: 1.1660 - val_categorical_accuracy: 0.7000 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", conv_model8.count_params())\n",
    "model8=conv_model8.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv3DModel9(frames_to_sample,image_height,image_width):\n",
    "    \n",
    "    Input_shape=(frames_to_sample,image_height,image_width,3)\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(16, (3,3,3), padding='same', input_shape=Input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "\n",
    "    model.add(Conv3D(32, (3, 3,3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "\n",
    "    model.add(Conv3D(64, (3, 3,3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "\n",
    "    model.add(Conv3D(128, (3, 3,3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu',kernel_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(5,activation='softmax'))\n",
    "    \n",
    "    optimiser = optimizers.Adam(learning_rate=0.0002)\n",
    "    model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of frames passed in each video :16\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_49 (Conv3D)          (None, 16, 120, 120, 16)  1312      \n",
      "                                                                 \n",
      " activation_49 (Activation)  (None, 16, 120, 120, 16)  0         \n",
      "                                                                 \n",
      " batch_normalization_54 (Bat  (None, 16, 120, 120, 16)  64       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_39 (MaxPoolin  (None, 8, 60, 60, 16)    0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_50 (Conv3D)          (None, 8, 60, 60, 32)     13856     \n",
      "                                                                 \n",
      " activation_50 (Activation)  (None, 8, 60, 60, 32)     0         \n",
      "                                                                 \n",
      " batch_normalization_55 (Bat  (None, 8, 60, 60, 32)    128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_40 (MaxPoolin  (None, 4, 30, 30, 32)    0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_51 (Conv3D)          (None, 4, 30, 30, 64)     55360     \n",
      "                                                                 \n",
      " activation_51 (Activation)  (None, 4, 30, 30, 64)     0         \n",
      "                                                                 \n",
      " batch_normalization_56 (Bat  (None, 4, 30, 30, 64)    256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_41 (MaxPoolin  (None, 2, 15, 15, 64)    0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_52 (Conv3D)          (None, 2, 15, 15, 128)    221312    \n",
      "                                                                 \n",
      " activation_52 (Activation)  (None, 2, 15, 15, 128)    0         \n",
      "                                                                 \n",
      " batch_normalization_57 (Bat  (None, 2, 15, 15, 128)   512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling3d_42 (MaxPoolin  (None, 1, 7, 7, 128)     0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               802944    \n",
      "                                                                 \n",
      " batch_normalization_58 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,096,901\n",
      "Trainable params: 1,096,165\n",
      "Non-trainable params: 736\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_idx,shape_h,shape_w,batch_size,num_epochs = model_vars([1,3,5,7,9,11,13,15,17,19,20,21,23,25,27,29],120,120,20,25)\n",
    "conv_model9=Conv3DModel9(frames_to_sample=len(img_idx),image_height=shape_h,image_width=shape_w)\n",
    "conv_model9.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch: 34\n",
      "validation_steps: 5\n"
     ]
    }
   ],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print(\"steps_per_epoch:\", steps_per_epoch)\n",
    "print(\"validation_steps:\", validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 1539909\n",
      "Source path =  /home/datasets/Project_data/train ; batch size = 20\n",
      "Epoch 1/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 3.8022 - categorical_accuracy: 0.4691Source path =  /home/datasets/Project_data/val ; batch size = 20\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5.03394, saving model to model_init_2024-07-0510_28_50.488551/model-00001-3.80217-0.46912-5.03394-0.21000.h5\n",
      "34/34 [==============================] - 153s 5s/step - loss: 3.8022 - categorical_accuracy: 0.4691 - val_loss: 5.0339 - val_categorical_accuracy: 0.2100 - lr: 2.0000e-04\n",
      "Epoch 2/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 3.0534 - categorical_accuracy: 0.7353\n",
      "Epoch 00002: val_loss did not improve from 5.03394\n",
      "34/34 [==============================] - 152s 5s/step - loss: 3.0534 - categorical_accuracy: 0.7353 - val_loss: 7.2607 - val_categorical_accuracy: 0.1800 - lr: 2.0000e-04\n",
      "Epoch 3/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 2.7986 - categorical_accuracy: 0.8221\n",
      "Epoch 00003: val_loss did not improve from 5.03394\n",
      "34/34 [==============================] - 152s 5s/step - loss: 2.7986 - categorical_accuracy: 0.8221 - val_loss: 8.7687 - val_categorical_accuracy: 0.2300 - lr: 2.0000e-04\n",
      "Epoch 4/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 2.5806 - categorical_accuracy: 0.8926\n",
      "Epoch 00004: val_loss did not improve from 5.03394\n",
      "34/34 [==============================] - 151s 5s/step - loss: 2.5806 - categorical_accuracy: 0.8926 - val_loss: 10.1941 - val_categorical_accuracy: 0.2600 - lr: 2.0000e-04\n",
      "Epoch 5/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 2.3957 - categorical_accuracy: 0.9338\n",
      "Epoch 00005: val_loss did not improve from 5.03394\n",
      "34/34 [==============================] - 153s 5s/step - loss: 2.3957 - categorical_accuracy: 0.9338 - val_loss: 11.8901 - val_categorical_accuracy: 0.2300 - lr: 2.0000e-04\n",
      "Epoch 6/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 2.2616 - categorical_accuracy: 0.9618\n",
      "Epoch 00006: val_loss did not improve from 5.03394\n",
      "34/34 [==============================] - 153s 5s/step - loss: 2.2616 - categorical_accuracy: 0.9618 - val_loss: 11.8381 - val_categorical_accuracy: 0.2100 - lr: 2.0000e-04\n",
      "Epoch 7/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 2.2080 - categorical_accuracy: 0.9485\n",
      "Epoch 00007: val_loss did not improve from 5.03394\n",
      "34/34 [==============================] - 152s 5s/step - loss: 2.2080 - categorical_accuracy: 0.9485 - val_loss: 11.7427 - val_categorical_accuracy: 0.2200 - lr: 2.0000e-04\n",
      "Epoch 8/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 2.1007 - categorical_accuracy: 0.9706\n",
      "Epoch 00008: val_loss did not improve from 5.03394\n",
      "34/34 [==============================] - 153s 5s/step - loss: 2.1007 - categorical_accuracy: 0.9706 - val_loss: 10.0172 - val_categorical_accuracy: 0.2500 - lr: 2.0000e-04\n",
      "Epoch 9/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 2.0451 - categorical_accuracy: 0.9706\n",
      "Epoch 00009: val_loss did not improve from 5.03394\n",
      "34/34 [==============================] - 153s 5s/step - loss: 2.0451 - categorical_accuracy: 0.9706 - val_loss: 10.2247 - val_categorical_accuracy: 0.1900 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.9286 - categorical_accuracy: 0.9647\n",
      "Epoch 00010: val_loss did not improve from 5.03394\n",
      "34/34 [==============================] - 153s 5s/step - loss: 1.9286 - categorical_accuracy: 0.9647 - val_loss: 7.4288 - val_categorical_accuracy: 0.1900 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.8547 - categorical_accuracy: 0.9632\n",
      "Epoch 00011: val_loss did not improve from 5.03394\n",
      "34/34 [==============================] - 153s 5s/step - loss: 1.8547 - categorical_accuracy: 0.9632 - val_loss: 5.8138 - val_categorical_accuracy: 0.2200 - lr: 2.0000e-04\n",
      "Epoch 12/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.7773 - categorical_accuracy: 0.9779\n",
      "Epoch 00012: val_loss improved from 5.03394 to 4.86508, saving model to model_init_2024-07-0510_28_50.488551/model-00012-1.77727-0.97794-4.86508-0.29000.h5\n",
      "34/34 [==============================] - 150s 5s/step - loss: 1.7773 - categorical_accuracy: 0.9779 - val_loss: 4.8651 - val_categorical_accuracy: 0.2900 - lr: 2.0000e-05\n",
      "Epoch 13/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.7776 - categorical_accuracy: 0.9735\n",
      "Epoch 00013: val_loss improved from 4.86508 to 4.36994, saving model to model_init_2024-07-0510_28_50.488551/model-00013-1.77757-0.97353-4.36994-0.26000.h5\n",
      "34/34 [==============================] - 150s 5s/step - loss: 1.7776 - categorical_accuracy: 0.9735 - val_loss: 4.3699 - val_categorical_accuracy: 0.2600 - lr: 2.0000e-05\n",
      "Epoch 14/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.7604 - categorical_accuracy: 0.9765\n",
      "Epoch 00014: val_loss improved from 4.36994 to 3.87763, saving model to model_init_2024-07-0510_28_50.488551/model-00014-1.76042-0.97647-3.87763-0.34000.h5\n",
      "34/34 [==============================] - 151s 5s/step - loss: 1.7604 - categorical_accuracy: 0.9765 - val_loss: 3.8776 - val_categorical_accuracy: 0.3400 - lr: 2.0000e-05\n",
      "Epoch 15/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.7502 - categorical_accuracy: 0.9765\n",
      "Epoch 00015: val_loss improved from 3.87763 to 3.19930, saving model to model_init_2024-07-0510_28_50.488551/model-00015-1.75019-0.97647-3.19930-0.45000.h5\n",
      "34/34 [==============================] - 161s 5s/step - loss: 1.7502 - categorical_accuracy: 0.9765 - val_loss: 3.1993 - val_categorical_accuracy: 0.4500 - lr: 2.0000e-05\n",
      "Epoch 16/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.7385 - categorical_accuracy: 0.9838\n",
      "Epoch 00016: val_loss improved from 3.19930 to 3.00065, saving model to model_init_2024-07-0510_28_50.488551/model-00016-1.73847-0.98382-3.00065-0.49000.h5\n",
      "34/34 [==============================] - 151s 5s/step - loss: 1.7385 - categorical_accuracy: 0.9838 - val_loss: 3.0007 - val_categorical_accuracy: 0.4900 - lr: 2.0000e-05\n",
      "Epoch 17/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.7322 - categorical_accuracy: 0.9794\n",
      "Epoch 00017: val_loss improved from 3.00065 to 2.68967, saving model to model_init_2024-07-0510_28_50.488551/model-00017-1.73218-0.97941-2.68967-0.62000.h5\n",
      "34/34 [==============================] - 151s 5s/step - loss: 1.7322 - categorical_accuracy: 0.9794 - val_loss: 2.6897 - val_categorical_accuracy: 0.6200 - lr: 2.0000e-05\n",
      "Epoch 18/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.7200 - categorical_accuracy: 0.9706\n",
      "Epoch 00018: val_loss improved from 2.68967 to 2.66131, saving model to model_init_2024-07-0510_28_50.488551/model-00018-1.71996-0.97059-2.66131-0.66000.h5\n",
      "34/34 [==============================] - 150s 5s/step - loss: 1.7200 - categorical_accuracy: 0.9706 - val_loss: 2.6613 - val_categorical_accuracy: 0.6600 - lr: 2.0000e-05\n",
      "Epoch 19/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.7144 - categorical_accuracy: 0.9794\n",
      "Epoch 00019: val_loss improved from 2.66131 to 2.49766, saving model to model_init_2024-07-0510_28_50.488551/model-00019-1.71438-0.97941-2.49766-0.68000.h5\n",
      "34/34 [==============================] - 151s 5s/step - loss: 1.7144 - categorical_accuracy: 0.9794 - val_loss: 2.4977 - val_categorical_accuracy: 0.6800 - lr: 2.0000e-05\n",
      "Epoch 20/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.7061 - categorical_accuracy: 0.9779\n",
      "Epoch 00020: val_loss improved from 2.49766 to 2.37781, saving model to model_init_2024-07-0510_28_50.488551/model-00020-1.70612-0.97794-2.37781-0.73000.h5\n",
      "34/34 [==============================] - 153s 5s/step - loss: 1.7061 - categorical_accuracy: 0.9779 - val_loss: 2.3778 - val_categorical_accuracy: 0.7300 - lr: 2.0000e-05\n",
      "Epoch 21/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.6936 - categorical_accuracy: 0.9779\n",
      "Epoch 00021: val_loss improved from 2.37781 to 2.36498, saving model to model_init_2024-07-0510_28_50.488551/model-00021-1.69359-0.97794-2.36498-0.72000.h5\n",
      "34/34 [==============================] - 152s 5s/step - loss: 1.6936 - categorical_accuracy: 0.9779 - val_loss: 2.3650 - val_categorical_accuracy: 0.7200 - lr: 2.0000e-05\n",
      "Epoch 22/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.6798 - categorical_accuracy: 0.9824\n",
      "Epoch 00022: val_loss improved from 2.36498 to 2.31631, saving model to model_init_2024-07-0510_28_50.488551/model-00022-1.67976-0.98235-2.31631-0.75000.h5\n",
      "34/34 [==============================] - 151s 5s/step - loss: 1.6798 - categorical_accuracy: 0.9824 - val_loss: 2.3163 - val_categorical_accuracy: 0.7500 - lr: 2.0000e-05\n",
      "Epoch 23/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.6721 - categorical_accuracy: 0.9750\n",
      "Epoch 00023: val_loss improved from 2.31631 to 2.14892, saving model to model_init_2024-07-0510_28_50.488551/model-00023-1.67209-0.97500-2.14892-0.81000.h5\n",
      "34/34 [==============================] - 152s 5s/step - loss: 1.6721 - categorical_accuracy: 0.9750 - val_loss: 2.1489 - val_categorical_accuracy: 0.8100 - lr: 2.0000e-05\n",
      "Epoch 24/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.6695 - categorical_accuracy: 0.9765\n",
      "Epoch 00024: val_loss did not improve from 2.14892\n",
      "34/34 [==============================] - 152s 5s/step - loss: 1.6695 - categorical_accuracy: 0.9765 - val_loss: 2.2283 - val_categorical_accuracy: 0.7700 - lr: 2.0000e-05\n",
      "Epoch 25/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.6510 - categorical_accuracy: 0.9750\n",
      "Epoch 00025: val_loss did not improve from 2.14892\n",
      "34/34 [==============================] - 180s 5s/step - loss: 1.6510 - categorical_accuracy: 0.9750 - val_loss: 2.2358 - val_categorical_accuracy: 0.7700 - lr: 2.0000e-05\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", conv_model8.count_params())\n",
    "model9=conv_model9.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import  Conv2D, MaxPooling2D\n",
    "from keras.layers import TimeDistributed,LSTM ,ConvLSTM2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv2DModel1(frames_to_sample,image_height,image_width):\n",
    "    \n",
    "    Input_shape=(frames_to_sample,image_height,image_width,3)\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv2D(16, (3,3), padding='same', activation='relu'), input_shape=Input_shape))\n",
    "    model.add(TimeDistributed(BatchNormalization()))\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2))))\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(32, (3,3), padding='same', activation='relu')))\n",
    "    model.add(TimeDistributed(BatchNormalization()))\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2))))\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(64, (3,3), padding='same', activation='relu')))\n",
    "    model.add(TimeDistributed(BatchNormalization()))\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2))))\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(128, (3,3), padding='same', activation='relu')))\n",
    "    model.add(TimeDistributed(BatchNormalization()))\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2))))\n",
    "\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(512)),\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(5,activation='softmax'))\n",
    "    \n",
    "    optimiser = optimizers.Adam(learning_rate=0.0002)\n",
    "    model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of frames passed in each video :16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-05 14:16:01.727034: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2024-07-05 14:16:01.727095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14800 MB memory:  -> device: 0, name: Quadro RTX 5000, pci bus id: 0000:1c:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed (TimeDistr  (None, 16, 120, 120, 16)  448      \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 16, 120, 120, 16)  64       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 16, 60, 60, 16)   0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, 16, 60, 60, 32)   4640      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 16, 60, 60, 32)   128       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDis  (None, 16, 30, 30, 32)   0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_6 (TimeDis  (None, 16, 30, 30, 64)   18496     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_7 (TimeDis  (None, 16, 30, 30, 64)   256       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_8 (TimeDis  (None, 16, 15, 15, 64)   0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_9 (TimeDis  (None, 16, 15, 15, 128)  73856     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_10 (TimeDi  (None, 16, 15, 15, 128)  512       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_11 (TimeDi  (None, 16, 7, 7, 128)    0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_12 (TimeDi  (None, 16, 6272)         0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 512)               13895680  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,996,645\n",
      "Trainable params: 13,996,165\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_idx,shape_h,shape_w,batch_size,num_epochs = model_vars([2,4,6,8,10,12,14,16,17,18,20,22,24,25,26,28],120,120,20,15)\n",
    "conv_model10=Conv2DModel1(frames_to_sample=len(img_idx),image_height=shape_h,image_width=shape_w)\n",
    "conv_model10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch: 34\n",
      "validation_steps: 5\n"
     ]
    }
   ],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print(\"steps_per_epoch:\", steps_per_epoch)\n",
    "print(\"validation_steps:\", validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 13996645\n",
      "Source path =  /home/datasets/Project_data/train ; batch size = 20\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-05 14:16:50.422042: I tensorflow/stream_executor/cuda/cuda_dnn.cc:377] Loaded cuDNN version 8302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - ETA: 0s - loss: 1.2659 - categorical_accuracy: 0.4824Source path =  /home/datasets/Project_data/val ; batch size = 20\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.65765, saving model to model_init_2024-07-0514_15_23.657879/model-00001-1.26591-0.48235-1.65765-0.28000.h5\n",
      "34/34 [==============================] - 165s 5s/step - loss: 1.2659 - categorical_accuracy: 0.4824 - val_loss: 1.6576 - val_categorical_accuracy: 0.2800 - lr: 2.0000e-04\n",
      "Epoch 2/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6045 - categorical_accuracy: 0.7838\n",
      "Epoch 00002: val_loss did not improve from 1.65765\n",
      "34/34 [==============================] - 150s 5s/step - loss: 0.6045 - categorical_accuracy: 0.7838 - val_loss: 1.9036 - val_categorical_accuracy: 0.1400 - lr: 2.0000e-04\n",
      "Epoch 3/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3810 - categorical_accuracy: 0.8721\n",
      "Epoch 00003: val_loss did not improve from 1.65765\n",
      "34/34 [==============================] - 148s 4s/step - loss: 0.3810 - categorical_accuracy: 0.8721 - val_loss: 1.8039 - val_categorical_accuracy: 0.1600 - lr: 2.0000e-04\n",
      "Epoch 4/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2420 - categorical_accuracy: 0.9485\n",
      "Epoch 00004: val_loss did not improve from 1.65765\n",
      "34/34 [==============================] - 146s 4s/step - loss: 0.2420 - categorical_accuracy: 0.9485 - val_loss: 1.8422 - val_categorical_accuracy: 0.1700 - lr: 2.0000e-04\n",
      "Epoch 5/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1703 - categorical_accuracy: 0.9632\n",
      "Epoch 00005: val_loss did not improve from 1.65765\n",
      "34/34 [==============================] - 147s 4s/step - loss: 0.1703 - categorical_accuracy: 0.9632 - val_loss: 1.9383 - val_categorical_accuracy: 0.2200 - lr: 2.0000e-04\n",
      "Epoch 6/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1060 - categorical_accuracy: 0.9750\n",
      "Epoch 00006: val_loss did not improve from 1.65765\n",
      "34/34 [==============================] - 147s 4s/step - loss: 0.1060 - categorical_accuracy: 0.9750 - val_loss: 2.0819 - val_categorical_accuracy: 0.2400 - lr: 2.0000e-04\n",
      "Epoch 7/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0834 - categorical_accuracy: 0.9779\n",
      "Epoch 00007: val_loss did not improve from 1.65765\n",
      "34/34 [==============================] - 147s 4s/step - loss: 0.0834 - categorical_accuracy: 0.9779 - val_loss: 2.3647 - val_categorical_accuracy: 0.2400 - lr: 2.0000e-04\n",
      "Epoch 8/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0803 - categorical_accuracy: 0.9691\n",
      "Epoch 00008: val_loss did not improve from 1.65765\n",
      "34/34 [==============================] - 148s 4s/step - loss: 0.0803 - categorical_accuracy: 0.9691 - val_loss: 2.6351 - val_categorical_accuracy: 0.2400 - lr: 2.0000e-04\n",
      "Epoch 9/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0881 - categorical_accuracy: 0.9750\n",
      "Epoch 00009: val_loss did not improve from 1.65765\n",
      "34/34 [==============================] - 146s 4s/step - loss: 0.0881 - categorical_accuracy: 0.9750 - val_loss: 2.4887 - val_categorical_accuracy: 0.3400 - lr: 2.0000e-04\n",
      "Epoch 10/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0742 - categorical_accuracy: 0.9706\n",
      "Epoch 00010: val_loss did not improve from 1.65765\n",
      "34/34 [==============================] - 148s 4s/step - loss: 0.0742 - categorical_accuracy: 0.9706 - val_loss: 3.0671 - val_categorical_accuracy: 0.2500 - lr: 2.0000e-04\n",
      "Epoch 11/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0773 - categorical_accuracy: 0.9750\n",
      "Epoch 00011: val_loss did not improve from 1.65765\n",
      "34/34 [==============================] - 148s 4s/step - loss: 0.0773 - categorical_accuracy: 0.9750 - val_loss: 2.4029 - val_categorical_accuracy: 0.3300 - lr: 2.0000e-04\n",
      "Epoch 12/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0485 - categorical_accuracy: 0.9721\n",
      "Epoch 00012: val_loss did not improve from 1.65765\n",
      "34/34 [==============================] - 147s 4s/step - loss: 0.0485 - categorical_accuracy: 0.9721 - val_loss: 2.2882 - val_categorical_accuracy: 0.3900 - lr: 2.0000e-05\n",
      "Epoch 13/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0417 - categorical_accuracy: 0.9765\n",
      "Epoch 00013: val_loss did not improve from 1.65765\n",
      "34/34 [==============================] - 147s 4s/step - loss: 0.0417 - categorical_accuracy: 0.9765 - val_loss: 1.7448 - val_categorical_accuracy: 0.5000 - lr: 2.0000e-05\n",
      "Epoch 14/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0360 - categorical_accuracy: 0.9824\n",
      "Epoch 00014: val_loss improved from 1.65765 to 1.52908, saving model to model_init_2024-07-0514_15_23.657879/model-00014-0.03599-0.98235-1.52908-0.50000.h5\n",
      "34/34 [==============================] - 148s 4s/step - loss: 0.0360 - categorical_accuracy: 0.9824 - val_loss: 1.5291 - val_categorical_accuracy: 0.5000 - lr: 2.0000e-05\n",
      "Epoch 15/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0354 - categorical_accuracy: 0.9765\n",
      "Epoch 00015: val_loss improved from 1.52908 to 1.34732, saving model to model_init_2024-07-0514_15_23.657879/model-00015-0.03540-0.97647-1.34732-0.52000.h5\n",
      "34/34 [==============================] - 148s 4s/step - loss: 0.0354 - categorical_accuracy: 0.9765 - val_loss: 1.3473 - val_categorical_accuracy: 0.5200 - lr: 2.0000e-05\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", conv_model10.count_params())\n",
    "model10=conv_model10.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv2DModel2(frames_to_sample,image_height,image_width):\n",
    "    \n",
    "    Input_shape=(frames_to_sample,image_height,image_width,3)\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv2D(16, (3,3), padding='same', activation='relu'), input_shape=Input_shape))\n",
    "    model.add(TimeDistributed(BatchNormalization()))\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2))))\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(32, (3,3), padding='same', activation='relu')))\n",
    "    model.add(TimeDistributed(BatchNormalization()))\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2))))\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(64, (3,3), padding='same', activation='relu')))\n",
    "    model.add(TimeDistributed(BatchNormalization()))\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2))))\n",
    "    \n",
    "    model.add(TimeDistributed(Conv2D(128, (3,3), padding='same', activation='relu')))\n",
    "    model.add(TimeDistributed(BatchNormalization()))\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2))))\n",
    "\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(GRU(512)),\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(5,activation='softmax'))\n",
    "    \n",
    "    optimiser = optimizers.Adam(learning_rate=0.0002)\n",
    "    model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of frames passed in each video :6\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_26 (TimeDi  (None, 6, 120, 120, 16)  448       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_27 (TimeDi  (None, 6, 120, 120, 16)  64        \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_28 (TimeDi  (None, 6, 60, 60, 16)    0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_29 (TimeDi  (None, 6, 60, 60, 32)    4640      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_30 (TimeDi  (None, 6, 60, 60, 32)    128       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_31 (TimeDi  (None, 6, 30, 30, 32)    0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_32 (TimeDi  (None, 6, 30, 30, 64)    18496     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_33 (TimeDi  (None, 6, 30, 30, 64)    256       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_34 (TimeDi  (None, 6, 15, 15, 64)    0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_35 (TimeDi  (None, 6, 15, 15, 128)   73856     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_36 (TimeDi  (None, 6, 15, 15, 128)   512       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_37 (TimeDi  (None, 6, 7, 7, 128)     0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_38 (TimeDi  (None, 6, 6272)          0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 512)               10423296  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,524,261\n",
      "Trainable params: 10,523,781\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_idx,shape_h,shape_w,batch_size,num_epochs = model_vars(list(range(0,30,5)),120,120,20,20)\n",
    "conv_model11=Conv2DModel2(frames_to_sample=len(img_idx),image_height=shape_h,image_width=shape_w)\n",
    "conv_model11.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch: 34\n",
      "validation_steps: 5\n"
     ]
    }
   ],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print(\"steps_per_epoch:\", steps_per_epoch)\n",
    "print(\"validation_steps:\", validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 10524261\n",
      "Source path =  /home/datasets/Project_data/train ; batch size = 20\n",
      "Epoch 1/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.3500 - categorical_accuracy: 0.4529Source path =  /home/datasets/Project_data/val ; batch size = 20\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.34732\n",
      "34/34 [==============================] - 66s 2s/step - loss: 1.3500 - categorical_accuracy: 0.4529 - val_loss: 1.6698 - val_categorical_accuracy: 0.2300 - lr: 2.0000e-04\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3806 - categorical_accuracy: 0.8529\n",
      "Epoch 00002: val_loss did not improve from 1.34732\n",
      "34/34 [==============================] - 55s 2s/step - loss: 0.3806 - categorical_accuracy: 0.8529 - val_loss: 1.8232 - val_categorical_accuracy: 0.2800 - lr: 2.0000e-04\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1780 - categorical_accuracy: 0.9441\n",
      "Epoch 00003: val_loss did not improve from 1.34732\n",
      "34/34 [==============================] - 55s 2s/step - loss: 0.1780 - categorical_accuracy: 0.9441 - val_loss: 2.2012 - val_categorical_accuracy: 0.2000 - lr: 2.0000e-04\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1067 - categorical_accuracy: 0.9632\n",
      "Epoch 00004: val_loss did not improve from 1.34732\n",
      "34/34 [==============================] - 55s 2s/step - loss: 0.1067 - categorical_accuracy: 0.9632 - val_loss: 1.9031 - val_categorical_accuracy: 0.2400 - lr: 2.0000e-04\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0937 - categorical_accuracy: 0.9735\n",
      "Epoch 00005: val_loss did not improve from 1.34732\n",
      "34/34 [==============================] - 55s 2s/step - loss: 0.0937 - categorical_accuracy: 0.9735 - val_loss: 1.9840 - val_categorical_accuracy: 0.3100 - lr: 2.0000e-04\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0879 - categorical_accuracy: 0.9632\n",
      "Epoch 00006: val_loss did not improve from 1.34732\n",
      "34/34 [==============================] - 55s 2s/step - loss: 0.0879 - categorical_accuracy: 0.9632 - val_loss: 2.0560 - val_categorical_accuracy: 0.2800 - lr: 2.0000e-04\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0908 - categorical_accuracy: 0.9706\n",
      "Epoch 00007: val_loss did not improve from 1.34732\n",
      "34/34 [==============================] - 54s 2s/step - loss: 0.0908 - categorical_accuracy: 0.9706 - val_loss: 2.3442 - val_categorical_accuracy: 0.3000 - lr: 2.0000e-04\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0764 - categorical_accuracy: 0.9691\n",
      "Epoch 00008: val_loss did not improve from 1.34732\n",
      "34/34 [==============================] - 54s 2s/step - loss: 0.0764 - categorical_accuracy: 0.9691 - val_loss: 1.9393 - val_categorical_accuracy: 0.3500 - lr: 2.0000e-04\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0825 - categorical_accuracy: 0.9662\n",
      "Epoch 00009: val_loss did not improve from 1.34732\n",
      "34/34 [==============================] - 55s 2s/step - loss: 0.0825 - categorical_accuracy: 0.9662 - val_loss: 2.1165 - val_categorical_accuracy: 0.3700 - lr: 2.0000e-04\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1046 - categorical_accuracy: 0.9544\n",
      "Epoch 00010: val_loss did not improve from 1.34732\n",
      "34/34 [==============================] - 54s 2s/step - loss: 0.1046 - categorical_accuracy: 0.9544 - val_loss: 1.7725 - val_categorical_accuracy: 0.4400 - lr: 2.0000e-04\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0815 - categorical_accuracy: 0.9691\n",
      "Epoch 00011: val_loss did not improve from 1.34732\n",
      "34/34 [==============================] - 55s 2s/step - loss: 0.0815 - categorical_accuracy: 0.9691 - val_loss: 1.8185 - val_categorical_accuracy: 0.4600 - lr: 2.0000e-04\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0323 - categorical_accuracy: 0.9765\n",
      "Epoch 00012: val_loss did not improve from 1.34732\n",
      "34/34 [==============================] - 59s 2s/step - loss: 0.0323 - categorical_accuracy: 0.9765 - val_loss: 1.5111 - val_categorical_accuracy: 0.4800 - lr: 2.0000e-05\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0330 - categorical_accuracy: 0.9779\n",
      "Epoch 00013: val_loss improved from 1.34732 to 1.34559, saving model to model_init_2024-07-0514_15_23.657879/model-00013-0.03302-0.97794-1.34559-0.55000.h5\n",
      "34/34 [==============================] - 55s 2s/step - loss: 0.0330 - categorical_accuracy: 0.9779 - val_loss: 1.3456 - val_categorical_accuracy: 0.5500 - lr: 2.0000e-05\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0316 - categorical_accuracy: 0.9750\n",
      "Epoch 00014: val_loss improved from 1.34559 to 1.31299, saving model to model_init_2024-07-0514_15_23.657879/model-00014-0.03160-0.97500-1.31299-0.51000.h5\n",
      "34/34 [==============================] - 54s 2s/step - loss: 0.0316 - categorical_accuracy: 0.9750 - val_loss: 1.3130 - val_categorical_accuracy: 0.5100 - lr: 2.0000e-05\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0327 - categorical_accuracy: 0.9750\n",
      "Epoch 00015: val_loss improved from 1.31299 to 1.12590, saving model to model_init_2024-07-0514_15_23.657879/model-00015-0.03267-0.97500-1.12590-0.56000.h5\n",
      "34/34 [==============================] - 55s 2s/step - loss: 0.0327 - categorical_accuracy: 0.9750 - val_loss: 1.1259 - val_categorical_accuracy: 0.5600 - lr: 2.0000e-05\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0359 - categorical_accuracy: 0.9750\n",
      "Epoch 00016: val_loss improved from 1.12590 to 1.02355, saving model to model_init_2024-07-0514_15_23.657879/model-00016-0.03585-0.97500-1.02355-0.64000.h5\n",
      "34/34 [==============================] - 54s 2s/step - loss: 0.0359 - categorical_accuracy: 0.9750 - val_loss: 1.0236 - val_categorical_accuracy: 0.6400 - lr: 2.0000e-05\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0345 - categorical_accuracy: 0.9779\n",
      "Epoch 00017: val_loss improved from 1.02355 to 0.97702, saving model to model_init_2024-07-0514_15_23.657879/model-00017-0.03452-0.97794-0.97702-0.62000.h5\n",
      "34/34 [==============================] - 54s 2s/step - loss: 0.0345 - categorical_accuracy: 0.9779 - val_loss: 0.9770 - val_categorical_accuracy: 0.6200 - lr: 2.0000e-05\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0352 - categorical_accuracy: 0.9735\n",
      "Epoch 00018: val_loss improved from 0.97702 to 0.87883, saving model to model_init_2024-07-0514_15_23.657879/model-00018-0.03520-0.97353-0.87883-0.67000.h5\n",
      "34/34 [==============================] - 55s 2s/step - loss: 0.0352 - categorical_accuracy: 0.9735 - val_loss: 0.8788 - val_categorical_accuracy: 0.6700 - lr: 2.0000e-05\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0363 - categorical_accuracy: 0.9824\n",
      "Epoch 00019: val_loss improved from 0.87883 to 0.79486, saving model to model_init_2024-07-0514_15_23.657879/model-00019-0.03635-0.98235-0.79486-0.69000.h5\n",
      "34/34 [==============================] - 54s 2s/step - loss: 0.0363 - categorical_accuracy: 0.9824 - val_loss: 0.7949 - val_categorical_accuracy: 0.6900 - lr: 2.0000e-05\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0359 - categorical_accuracy: 0.9765\n",
      "Epoch 00020: val_loss improved from 0.79486 to 0.75231, saving model to model_init_2024-07-0514_15_23.657879/model-00020-0.03586-0.97647-0.75231-0.71000.h5\n",
      "34/34 [==============================] - 55s 2s/step - loss: 0.0359 - categorical_accuracy: 0.9765 - val_loss: 0.7523 - val_categorical_accuracy: 0.7100 - lr: 2.0000e-05\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", conv_model11.count_params())\n",
    "model11=conv_model11.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import  Conv2D, MaxPooling2D\n",
    "from keras.layers import TimeDistributed,LSTM ,ConvLSTM2D\n",
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv2DModel3(frames_to_sample,image_height,image_width):\n",
    "    \n",
    "    Input_shape=(frames_to_sample,image_height,image_width,3)\n",
    "    # Get base model \n",
    "    # Here we are using ResNet50 as base model\n",
    "    transfer_model = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(transfer_model, input_shape=Input_shape))\n",
    "    model.add(TimeDistributed(BatchNormalization()))\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2))))\n",
    "    \n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(GRU(128)),\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(5,activation='softmax'))\n",
    "    \n",
    "    optimiser = optimizers.Adam(learning_rate=0.0002)\n",
    "    model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of frames passed in each video :10\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_39 (TimeDi  (None, 10, 4, 4, 2048)   23587712  \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_40 (TimeDi  (None, 10, 4, 4, 2048)   8192      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_41 (TimeDi  (None, 10, 2, 2, 2048)   0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_42 (TimeDi  (None, 10, 8192)         0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 128)               3195648   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,792,197\n",
      "Trainable params: 26,734,981\n",
      "Non-trainable params: 57,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_idx,shape_h,shape_w,batch_size,num_epochs = model_vars(list(range(0,30,3)),120,120,20,15)\n",
    "conv_model12=Conv2DModel3(frames_to_sample=len(img_idx),image_height=shape_h,image_width=shape_w)\n",
    "conv_model12.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch: 34\n",
      "validation_steps: 5\n"
     ]
    }
   ],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print(\"steps_per_epoch:\", steps_per_epoch)\n",
    "print(\"validation_steps:\", validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 26792197\n",
      "Source path =  /home/datasets/Project_data/train ; batch size = 20\n",
      "Epoch 1/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0717 - categorical_accuracy: 0.5632Source path =  /home/datasets/Project_data/val ; batch size = 20\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.75231\n",
      "34/34 [==============================] - 110s 3s/step - loss: 1.0717 - categorical_accuracy: 0.5632 - val_loss: 1.9596 - val_categorical_accuracy: 0.2100 - lr: 2.0000e-04\n",
      "Epoch 2/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1609 - categorical_accuracy: 0.9250\n",
      "Epoch 00002: val_loss did not improve from 0.75231\n",
      "34/34 [==============================] - 93s 3s/step - loss: 0.1609 - categorical_accuracy: 0.9250 - val_loss: 1.9327 - val_categorical_accuracy: 0.1500 - lr: 2.0000e-04\n",
      "Epoch 3/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0594 - categorical_accuracy: 0.9706\n",
      "Epoch 00003: val_loss did not improve from 0.75231\n",
      "34/34 [==============================] - 93s 3s/step - loss: 0.0594 - categorical_accuracy: 0.9706 - val_loss: 1.8021 - val_categorical_accuracy: 0.2500 - lr: 2.0000e-04\n",
      "Epoch 4/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0746 - categorical_accuracy: 0.9676\n",
      "Epoch 00004: val_loss did not improve from 0.75231\n",
      "34/34 [==============================] - 93s 3s/step - loss: 0.0746 - categorical_accuracy: 0.9676 - val_loss: 2.0916 - val_categorical_accuracy: 0.1800 - lr: 2.0000e-04\n",
      "Epoch 5/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0576 - categorical_accuracy: 0.9632\n",
      "Epoch 00005: val_loss did not improve from 0.75231\n",
      "34/34 [==============================] - 93s 3s/step - loss: 0.0576 - categorical_accuracy: 0.9632 - val_loss: 1.7148 - val_categorical_accuracy: 0.2200 - lr: 2.0000e-04\n",
      "Epoch 6/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0666 - categorical_accuracy: 0.9676\n",
      "Epoch 00006: val_loss did not improve from 0.75231\n",
      "34/34 [==============================] - 93s 3s/step - loss: 0.0666 - categorical_accuracy: 0.9676 - val_loss: 1.7594 - val_categorical_accuracy: 0.2300 - lr: 2.0000e-04\n",
      "Epoch 7/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0649 - categorical_accuracy: 0.9706\n",
      "Epoch 00007: val_loss did not improve from 0.75231\n",
      "34/34 [==============================] - 92s 3s/step - loss: 0.0649 - categorical_accuracy: 0.9706 - val_loss: 1.8144 - val_categorical_accuracy: 0.1900 - lr: 2.0000e-04\n",
      "Epoch 8/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0706 - categorical_accuracy: 0.9647\n",
      "Epoch 00008: val_loss did not improve from 0.75231\n",
      "34/34 [==============================] - 92s 3s/step - loss: 0.0706 - categorical_accuracy: 0.9647 - val_loss: 2.1264 - val_categorical_accuracy: 0.1700 - lr: 2.0000e-04\n",
      "Epoch 9/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0567 - categorical_accuracy: 0.9662\n",
      "Epoch 00009: val_loss did not improve from 0.75231\n",
      "34/34 [==============================] - 92s 3s/step - loss: 0.0567 - categorical_accuracy: 0.9662 - val_loss: 2.2372 - val_categorical_accuracy: 0.1500 - lr: 2.0000e-04\n",
      "Epoch 10/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0459 - categorical_accuracy: 0.9721\n",
      "Epoch 00010: val_loss did not improve from 0.75231\n",
      "34/34 [==============================] - 93s 3s/step - loss: 0.0459 - categorical_accuracy: 0.9721 - val_loss: 1.9354 - val_categorical_accuracy: 0.3400 - lr: 2.0000e-04\n",
      "Epoch 11/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0501 - categorical_accuracy: 0.9765\n",
      "Epoch 00011: val_loss did not improve from 0.75231\n",
      "34/34 [==============================] - 92s 3s/step - loss: 0.0501 - categorical_accuracy: 0.9765 - val_loss: 1.7155 - val_categorical_accuracy: 0.4500 - lr: 2.0000e-04\n",
      "Epoch 12/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0539 - categorical_accuracy: 0.9721\n",
      "Epoch 00012: val_loss did not improve from 0.75231\n",
      "34/34 [==============================] - 92s 3s/step - loss: 0.0539 - categorical_accuracy: 0.9721 - val_loss: 1.4164 - val_categorical_accuracy: 0.4700 - lr: 2.0000e-04\n",
      "Epoch 13/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0689 - categorical_accuracy: 0.9618\n",
      "Epoch 00013: val_loss did not improve from 0.75231\n",
      "34/34 [==============================] - 92s 3s/step - loss: 0.0689 - categorical_accuracy: 0.9618 - val_loss: 1.2228 - val_categorical_accuracy: 0.6100 - lr: 2.0000e-04\n",
      "Epoch 14/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0534 - categorical_accuracy: 0.9721\n",
      "Epoch 00014: val_loss did not improve from 0.75231\n",
      "34/34 [==============================] - 94s 3s/step - loss: 0.0534 - categorical_accuracy: 0.9721 - val_loss: 1.3865 - val_categorical_accuracy: 0.5600 - lr: 2.0000e-04\n",
      "Epoch 15/15\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0493 - categorical_accuracy: 0.9735\n",
      "Epoch 00015: val_loss did not improve from 0.75231\n",
      "34/34 [==============================] - 95s 3s/step - loss: 0.0493 - categorical_accuracy: 0.9735 - val_loss: 1.0626 - val_categorical_accuracy: 0.6600 - lr: 2.0000e-04\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", conv_model12.count_params())\n",
    "model12=conv_model12.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import  Conv2D, MaxPooling2D\n",
    "from keras.layers import TimeDistributed,LSTM ,ConvLSTM2D\n",
    "from tensorflow.keras.applications import mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv2DModel4(frames_to_sample,image_height,image_width):\n",
    "    \n",
    "    Input_shape=(frames_to_sample,image_height,image_width,3)\n",
    "    # Get base model \n",
    "    # Here we are using mobilenet_transfer as base model\n",
    "    transfer_model = mobilenet.MobileNet(weights='imagenet', include_top=False)\n",
    "    #transfer_model = mobilenet_transfer(weights='imagenet', include_top=False)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(transfer_model, input_shape=Input_shape))\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "            \n",
    "    model.add(TimeDistributed(BatchNormalization()))\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2))))\n",
    "    \n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(GRU(128)),\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(5,activation='softmax'))\n",
    "    \n",
    "    optimiser = optimizers.Adam(learning_rate=0.0002)\n",
    "    model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of frames passed in each video :10\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_47 (TimeDi  (None, 10, 3, 3, 1024)   3228864   \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_48 (TimeDi  (None, 10, 3, 3, 1024)   4096      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_49 (TimeDi  (None, 10, 1, 1, 1024)   0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_50 (TimeDi  (None, 10, 1024)         0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " gru_4 (GRU)                 (None, 128)               443136    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,676,741\n",
      "Trainable params: 445,829\n",
      "Non-trainable params: 3,230,912\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_idx,shape_h,shape_w,batch_size,num_epochs = model_vars(list(range(0,30,3)),120,120,20,25)\n",
    "conv_model13=Conv2DModel4(frames_to_sample=len(img_idx),image_height=shape_h,image_width=shape_w)\n",
    "conv_model13.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch: 34\n",
      "validation_steps: 5\n"
     ]
    }
   ],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "print(\"steps_per_epoch:\", steps_per_epoch)\n",
    "print(\"validation_steps:\", validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 3676741\n",
      "Source path =  /home/datasets/Project_data/train ; batch size = 20\n",
      "Epoch 1/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.6752 - categorical_accuracy: 0.3088Source path =  /home/datasets/Project_data/val ; batch size = 20\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.66996\n",
      "34/34 [==============================] - 97s 3s/step - loss: 1.6752 - categorical_accuracy: 0.3088 - val_loss: 1.2908 - val_categorical_accuracy: 0.4600 - lr: 2.0000e-04\n",
      "Epoch 2/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0461 - categorical_accuracy: 0.5868\n",
      "Epoch 00002: val_loss did not improve from 0.66996\n",
      "34/34 [==============================] - 94s 3s/step - loss: 1.0461 - categorical_accuracy: 0.5868 - val_loss: 1.0793 - val_categorical_accuracy: 0.5600 - lr: 2.0000e-04\n",
      "Epoch 3/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.7451 - categorical_accuracy: 0.7162\n",
      "Epoch 00003: val_loss did not improve from 0.66996\n",
      "34/34 [==============================] - 93s 3s/step - loss: 0.7451 - categorical_accuracy: 0.7162 - val_loss: 0.8921 - val_categorical_accuracy: 0.7000 - lr: 2.0000e-04\n",
      "Epoch 4/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.5424 - categorical_accuracy: 0.8426\n",
      "Epoch 00004: val_loss did not improve from 0.66996\n",
      "34/34 [==============================] - 94s 3s/step - loss: 0.5424 - categorical_accuracy: 0.8426 - val_loss: 0.8371 - val_categorical_accuracy: 0.6700 - lr: 2.0000e-04\n",
      "Epoch 5/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.4535 - categorical_accuracy: 0.8735\n",
      "Epoch 00005: val_loss did not improve from 0.66996\n",
      "34/34 [==============================] - 94s 3s/step - loss: 0.4535 - categorical_accuracy: 0.8735 - val_loss: 0.8457 - val_categorical_accuracy: 0.6800 - lr: 2.0000e-04\n",
      "Epoch 6/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3471 - categorical_accuracy: 0.9132\n",
      "Epoch 00006: val_loss did not improve from 0.66996\n",
      "34/34 [==============================] - 94s 3s/step - loss: 0.3471 - categorical_accuracy: 0.9132 - val_loss: 0.7754 - val_categorical_accuracy: 0.7000 - lr: 2.0000e-04\n",
      "Epoch 7/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2899 - categorical_accuracy: 0.9265\n",
      "Epoch 00007: val_loss did not improve from 0.66996\n",
      "34/34 [==============================] - 95s 3s/step - loss: 0.2899 - categorical_accuracy: 0.9265 - val_loss: 0.7189 - val_categorical_accuracy: 0.7800 - lr: 2.0000e-04\n",
      "Epoch 8/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2379 - categorical_accuracy: 0.9574\n",
      "Epoch 00008: val_loss did not improve from 0.66996\n",
      "34/34 [==============================] - 94s 3s/step - loss: 0.2379 - categorical_accuracy: 0.9574 - val_loss: 0.7664 - val_categorical_accuracy: 0.7200 - lr: 2.0000e-04\n",
      "Epoch 9/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2121 - categorical_accuracy: 0.9706\n",
      "Epoch 00009: val_loss improved from 0.66996 to 0.66130, saving model to model_init_2024-07-0514_15_23.657879/model-00009-0.21213-0.97059-0.66130-0.75000.h5\n",
      "34/34 [==============================] - 94s 3s/step - loss: 0.2121 - categorical_accuracy: 0.9706 - val_loss: 0.6613 - val_categorical_accuracy: 0.7500 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1655 - categorical_accuracy: 0.9647\n",
      "Epoch 00010: val_loss did not improve from 0.66130\n",
      "34/34 [==============================] - 94s 3s/step - loss: 0.1655 - categorical_accuracy: 0.9647 - val_loss: 0.8189 - val_categorical_accuracy: 0.6400 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1462 - categorical_accuracy: 0.9676\n",
      "Epoch 00011: val_loss did not improve from 0.66130\n",
      "34/34 [==============================] - 94s 3s/step - loss: 0.1462 - categorical_accuracy: 0.9676 - val_loss: 0.7039 - val_categorical_accuracy: 0.7200 - lr: 2.0000e-04\n",
      "Epoch 12/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1259 - categorical_accuracy: 0.9676\n",
      "Epoch 00012: val_loss improved from 0.66130 to 0.65821, saving model to model_init_2024-07-0514_15_23.657879/model-00012-0.12590-0.96765-0.65821-0.74000.h5\n",
      "34/34 [==============================] - 94s 3s/step - loss: 0.1259 - categorical_accuracy: 0.9676 - val_loss: 0.6582 - val_categorical_accuracy: 0.7400 - lr: 2.0000e-04\n",
      "Epoch 13/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1221 - categorical_accuracy: 0.9691\n",
      "Epoch 00013: val_loss did not improve from 0.65821\n",
      "34/34 [==============================] - 94s 3s/step - loss: 0.1221 - categorical_accuracy: 0.9691 - val_loss: 0.7273 - val_categorical_accuracy: 0.7100 - lr: 2.0000e-04\n",
      "Epoch 14/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1034 - categorical_accuracy: 0.9706\n",
      "Epoch 00014: val_loss did not improve from 0.65821\n",
      "34/34 [==============================] - 96s 3s/step - loss: 0.1034 - categorical_accuracy: 0.9706 - val_loss: 0.7498 - val_categorical_accuracy: 0.6500 - lr: 2.0000e-04\n",
      "Epoch 15/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0971 - categorical_accuracy: 0.9765\n",
      "Epoch 00015: val_loss improved from 0.65821 to 0.64974, saving model to model_init_2024-07-0514_15_23.657879/model-00015-0.09710-0.97647-0.64974-0.73000.h5\n",
      "34/34 [==============================] - 95s 3s/step - loss: 0.0971 - categorical_accuracy: 0.9765 - val_loss: 0.6497 - val_categorical_accuracy: 0.7300 - lr: 2.0000e-04\n",
      "Epoch 16/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0865 - categorical_accuracy: 0.9809\n",
      "Epoch 00016: val_loss did not improve from 0.64974\n",
      "34/34 [==============================] - 95s 3s/step - loss: 0.0865 - categorical_accuracy: 0.9809 - val_loss: 0.7006 - val_categorical_accuracy: 0.7400 - lr: 2.0000e-04\n",
      "Epoch 17/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0828 - categorical_accuracy: 0.9809\n",
      "Epoch 00017: val_loss did not improve from 0.64974\n",
      "34/34 [==============================] - 108s 3s/step - loss: 0.0828 - categorical_accuracy: 0.9809 - val_loss: 0.6682 - val_categorical_accuracy: 0.7400 - lr: 2.0000e-04\n",
      "Epoch 18/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0754 - categorical_accuracy: 0.9750\n",
      "Epoch 00018: val_loss did not improve from 0.64974\n",
      "34/34 [==============================] - 92s 3s/step - loss: 0.0754 - categorical_accuracy: 0.9750 - val_loss: 0.6683 - val_categorical_accuracy: 0.7500 - lr: 2.0000e-04\n",
      "Epoch 19/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0715 - categorical_accuracy: 0.9750\n",
      "Epoch 00019: val_loss did not improve from 0.64974\n",
      "34/34 [==============================] - 92s 3s/step - loss: 0.0715 - categorical_accuracy: 0.9750 - val_loss: 0.8212 - val_categorical_accuracy: 0.6900 - lr: 2.0000e-04\n",
      "Epoch 20/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0728 - categorical_accuracy: 0.9779\n",
      "Epoch 00020: val_loss did not improve from 0.64974\n",
      "34/34 [==============================] - 93s 3s/step - loss: 0.0728 - categorical_accuracy: 0.9779 - val_loss: 0.6881 - val_categorical_accuracy: 0.7600 - lr: 2.0000e-04\n",
      "Epoch 21/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0672 - categorical_accuracy: 0.9765\n",
      "Epoch 00021: val_loss did not improve from 0.64974\n",
      "34/34 [==============================] - 92s 3s/step - loss: 0.0672 - categorical_accuracy: 0.9765 - val_loss: 0.7091 - val_categorical_accuracy: 0.7600 - lr: 2.0000e-04\n",
      "Epoch 22/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0659 - categorical_accuracy: 0.9765\n",
      "Epoch 00022: val_loss did not improve from 0.64974\n",
      "34/34 [==============================] - 92s 3s/step - loss: 0.0659 - categorical_accuracy: 0.9765 - val_loss: 0.6861 - val_categorical_accuracy: 0.7700 - lr: 2.0000e-04\n",
      "Epoch 23/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0616 - categorical_accuracy: 0.9809\n",
      "Epoch 00023: val_loss did not improve from 0.64974\n",
      "34/34 [==============================] - 93s 3s/step - loss: 0.0616 - categorical_accuracy: 0.9809 - val_loss: 0.7912 - val_categorical_accuracy: 0.7000 - lr: 2.0000e-04\n",
      "Epoch 24/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0633 - categorical_accuracy: 0.9765\n",
      "Epoch 00024: val_loss did not improve from 0.64974\n",
      "34/34 [==============================] - 92s 3s/step - loss: 0.0633 - categorical_accuracy: 0.9765 - val_loss: 0.7478 - val_categorical_accuracy: 0.6900 - lr: 2.0000e-04\n",
      "Epoch 25/25\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0587 - categorical_accuracy: 0.9779\n",
      "Epoch 00025: val_loss did not improve from 0.64974\n",
      "34/34 [==============================] - 93s 3s/step - loss: 0.0587 - categorical_accuracy: 0.9779 - val_loss: 0.6776 - val_categorical_accuracy: 0.7600 - lr: 2.0000e-04\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", conv_model13.count_params())\n",
    "model13=conv_model13.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
